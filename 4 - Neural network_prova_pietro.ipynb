{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4 - Neural network_prova_pietro.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8uVLVSOdQlfw","colab_type":"code","colab":{}},"source":["%%capture\n","!pip install talos"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yMiHkFD7D5V8","colab_type":"text"},"source":["# Import dataset from Google Drive"]},{"cell_type":"code","metadata":{"id":"NhgQmzp4D1Z-","colab_type":"code","outputId":"1c7ceaaf-9280-4894-b57d-8345293e6f84","executionInfo":{"status":"ok","timestamp":1580728441812,"user_tz":-60,"elapsed":3445,"user":{"displayName":"Pietro Colombo","photoUrl":"","userId":"03586676689308284073"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# pietro\n","output_preprocessing = pd.read_csv(\"/content/drive/My Drive/UnimiB/Magistrale/Secondo Anno/Advanced Machine Learning/Progetto AML/output_preprocessing_50_clusters.csv\")\n","# carlo\n","#output_preprocessing = pd.read_csv(\"/content/drive/My Drive/universita/magistrale/advanced_machine_learning/Progetto AML/output_preprocessing_50_clusters.csv\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Lu-IdgZygjk1","colab_type":"text"},"source":["# Keras train test definition"]},{"cell_type":"code","metadata":{"id":"dlJbVA0qs7kn","colab_type":"code","colab":{}},"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","cols = list(output_preprocessing.columns.values)\n","cols.remove('trip_duration')\n","\n","target = output_preprocessing.loc[:, 'trip_duration']\n","features = output_preprocessing.loc[:, cols]\n","\n","train_features, test_features, train_target, test_target = \\\n","    train_test_split(features, target, test_size=0.20, random_state=0)\n","\n","train_x, train_y = np.array(train_features), np.array(train_target)\n","test_x, test_y = np.array(test_features), np.array(test_target)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","train_scaled_x = scaler.fit_transform(train_x)\n","test_scaled_x = scaler.transform(test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yeRzHWEgCFR3","colab_type":"text"},"source":["# Model "]},{"cell_type":"code","metadata":{"id":"v4PQ4npgQqkt","colab_type":"code","outputId":"236b11ce-2c30-4b41-fdc1-00cce00984c0","executionInfo":{"status":"ok","timestamp":1580728451577,"user_tz":-60,"elapsed":1833,"user":{"displayName":"Pietro Colombo","photoUrl":"","userId":"03586676689308284073"}},"colab":{"base_uri":"https://localhost:8080/","height":531}},"source":["from keras.layers.core import Dense, Dropout, Activation\n","from keras.models import Sequential\n","from keras.utils import np_utils\n","from talos.utils import hidden_layers\n","\n","\n","def model_def (x_train, y_train, x_val, y_val, params):\n","  num_features = x_train.shape[1]\n","\n","  model = Sequential()\n","  model.add(Dense(126, input_dim=num_features, activation='relu'))\n","\n","  model.add(Dense(32, activation='relu'))\n","\n","  model.add(Dense(64, activation='relu'))\n","\n","\n","  #model.add(Dropout(params['dropout']))\n","  \n","  #hidden_layers(model, params, 1)\n","  \n","  model.add(Dense(1, activation = 'relu'))\n","  model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'],params['optimizer'])), loss=params['loss'], metrics=['mse', 'mae', 'mape', 'cosine'])\n","  model.summary()\n","  history = model.fit(x_train, train_y,\n","                      validation_data=[x_val, y_val],\n","                      epochs=params['epochs'],\n","                      batch_size=params['batch_size'],\n","                      verbose=True)\n","  \n","  return history, model"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"OZXBwHjBEUmv","colab_type":"code","colab":{}},"source":["from talos.utils import lr_normalizer\n","from keras.optimizers import Adam, Nadam, RMSprop\n","from keras.activations import softmax, relu, elu, sigmoid\n","from keras.losses import mean_squared_error\n","\n","p = {'lr': (0.5, 5, 10),\n","     'first_neuron':[32, 64, 128, 256],\n","     'hidden_layers':[0, 1, 2],\n","     'shapes': ['brick'],\n","     'batch_size': [64, 128, 256],\n","     'epochs': [20],\n","     'dropout': (0, 0.5, 5),\n","     'weight_regulizer':[None],\n","     'emb_output_dims': [None],\n","     'shape':['brick','long_funnel'],\n","     'optimizer': [Adam],\n","     'loss': [mean_squared_error],\n","     'activation':[relu],\n","     'last_activation': [relu]}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GE5FoauFHNsh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4fa01299-8a12-4c0f-a41f-82183b27e757","executionInfo":{"status":"ok","timestamp":1580740896741,"user_tz":-60,"elapsed":12204502,"user":{"displayName":"Pietro Colombo","photoUrl":"","userId":"03586676689308284073"}}},"source":["import talos\n","from talos.utils import lr_normalizer\n","\n","t = talos.Scan(x=train_scaled_x,\n","            y=np.log(train_y + 1),\n","            x_val = test_scaled_x,\n","            y_val = np.log(test_y + 1),\n","            model=model_def,\n","            fraction_limit=0.01, \n","            params=p,\n","            experiment_name='taxi',\n","            #experiment_no='1'\n","            )"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","  0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_17 (Dense)             (None, 126)               2772      \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 32)                4064      \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 64)                2112      \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 181207.4379 - mse: 181207.4219 - mae: 275.0143 - mape: 45.2985 - cosine: 0.9997 - val_loss: 1010601.5867 - val_mse: 1010600.7500 - val_mae: 853.4366 - val_mape: 12639.4854 - val_cosine: 0.9995\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 134214.6610 - mse: 134214.7344 - mae: 234.3471 - mape: 36.4814 - cosine: 0.9994 - val_loss: 996075.8525 - val_mse: 996077.2500 - val_mae: 833.6254 - val_mape: 12300.0225 - val_cosine: 0.9992\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 125698.1576 - mse: 125697.5703 - mae: 226.1966 - mape: 35.4417 - cosine: 0.9989 - val_loss: 1025243.5706 - val_mse: 1025244.0625 - val_mae: 835.9961 - val_mape: 12305.1699 - val_cosine: 0.9991\n","Epoch 4/20\n","1156982/1156982 [==============================] - 17s 14us/step - loss: 121784.5778 - mse: 121784.4531 - mae: 221.9136 - mape: 34.6397 - cosine: 0.9996 - val_loss: 986715.7184 - val_mse: 986715.6250 - val_mae: 823.1927 - val_mape: 12128.1826 - val_cosine: 0.9998\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 120012.8798 - mse: 120012.8125 - mae: 219.9317 - mape: 34.3016 - cosine: 0.9998 - val_loss: 932103.1974 - val_mse: 932102.3750 - val_mae: 795.1511 - val_mape: 11698.2070 - val_cosine: 0.9999\n","Epoch 6/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 118754.5388 - mse: 118754.9141 - mae: 218.5604 - mape: 34.1125 - cosine: 0.9999 - val_loss: 935456.8035 - val_mse: 935456.6875 - val_mae: 798.0283 - val_mape: 11742.5859 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 17s 14us/step - loss: 117699.6197 - mse: 117699.8516 - mae: 217.4229 - mape: 33.9892 - cosine: 1.0000 - val_loss: 1035756.0161 - val_mse: 1035756.9375 - val_mae: 843.9178 - val_mape: 12431.5322 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 116747.9637 - mse: 116747.9219 - mae: 216.4375 - mape: 33.9206 - cosine: 1.0000 - val_loss: 983623.5863 - val_mse: 983624.8125 - val_mae: 825.9000 - val_mape: 12178.5713 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115763.9873 - mse: 115763.9688 - mae: 215.4042 - mape: 33.7957 - cosine: 1.0000 - val_loss: 983012.0114 - val_mse: 983012.5625 - val_mae: 827.9064 - val_mape: 12211.2627 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115029.1410 - mse: 115029.0000 - mae: 214.6453 - mape: 33.6973 - cosine: 1.0000 - val_loss: 1056264.4350 - val_mse: 1056264.7500 - val_mae: 865.8003 - val_mape: 12788.8447 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 17s 15us/step - loss: 114392.5099 - mse: 114392.5547 - mae: 214.0433 - mape: 33.6081 - cosine: 1.0000 - val_loss: 1002707.5793 - val_mse: 1002707.6250 - val_mae: 828.7971 - val_mape: 12205.4844 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 17s 14us/step - loss: 113720.7675 - mse: 113720.8750 - mae: 213.3987 - mape: 33.5538 - cosine: 1.0000 - val_loss: 1048711.4887 - val_mse: 1048710.5000 - val_mae: 857.4302 - val_mape: 12647.1475 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 112940.4509 - mse: 112940.4766 - mae: 212.6480 - mape: 33.4536 - cosine: 1.0000 - val_loss: 1021886.5920 - val_mse: 1021885.7500 - val_mae: 846.4429 - val_mape: 12491.0127 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 112281.6130 - mse: 112281.5859 - mae: 212.0014 - mape: 33.3712 - cosine: 1.0000 - val_loss: 1065416.3815 - val_mse: 1065416.3750 - val_mae: 851.2948 - val_mape: 12534.0537 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111593.3081 - mse: 111593.4375 - mae: 211.3577 - mape: 33.2997 - cosine: 1.0000 - val_loss: 1035482.8231 - val_mse: 1035481.7500 - val_mae: 829.3059 - val_mape: 12182.6934 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111121.3970 - mse: 111121.5703 - mae: 210.9095 - mape: 33.2395 - cosine: 1.0000 - val_loss: 1025222.9041 - val_mse: 1025223.3125 - val_mae: 844.4597 - val_mape: 12451.4570 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110663.6259 - mse: 110663.7500 - mae: 210.4288 - mape: 33.1662 - cosine: 1.0000 - val_loss: 1083212.5218 - val_mse: 1083211.6250 - val_mae: 857.6657 - val_mape: 12618.0010 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110303.5729 - mse: 110303.4219 - mae: 209.9375 - mape: 33.0395 - cosine: 1.0000 - val_loss: 1003380.4756 - val_mse: 1003380.6875 - val_mae: 829.3254 - val_mape: 12211.7832 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109926.8214 - mse: 109927.0859 - mae: 209.5736 - mape: 32.9966 - cosine: 1.0000 - val_loss: 1010968.5922 - val_mse: 1010969.0625 - val_mae: 827.1999 - val_mape: 12169.6162 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109625.3528 - mse: 109625.6250 - mae: 209.2330 - mape: 32.9320 - cosine: 1.0000 - val_loss: 1033309.7558 - val_mse: 1033311.3125 - val_mae: 833.5414 - val_mape: 12256.0254 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","  3%|▎         | 1/36 [05:28<3:11:45, 328.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 142366.1161 - mse: 142366.0000 - mae: 242.9025 - mape: 39.3542 - cosine: 1.0000 - val_loss: 1077703.2811 - val_mse: 1077703.6250 - val_mae: 873.9182 - val_mape: 12914.6504 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 120421.8986 - mse: 120421.9688 - mae: 220.7927 - mape: 34.8499 - cosine: 1.0000 - val_loss: 952908.2485 - val_mse: 952908.0000 - val_mae: 821.5817 - val_mape: 12135.5547 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 117697.3705 - mse: 117697.0703 - mae: 217.7561 - mape: 34.4328 - cosine: 1.0000 - val_loss: 949850.4413 - val_mse: 949849.4375 - val_mae: 797.0765 - val_mape: 11720.2617 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 114926.6603 - mse: 114926.7656 - mae: 214.7988 - mape: 34.0268 - cosine: 1.0000 - val_loss: 996251.4550 - val_mse: 996251.2500 - val_mae: 818.4844 - val_mape: 12035.2109 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 112361.6832 - mse: 112361.8125 - mae: 211.9386 - mape: 33.5233 - cosine: 1.0000 - val_loss: 1022781.3112 - val_mse: 1022782.1875 - val_mae: 848.7094 - val_mape: 12522.1084 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110907.3501 - mse: 110907.4062 - mae: 210.3652 - mape: 33.1916 - cosine: 1.0000 - val_loss: 1016662.8158 - val_mse: 1016664.0000 - val_mae: 831.9219 - val_mape: 12238.2510 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109927.9471 - mse: 109927.9531 - mae: 209.4541 - mape: 33.0298 - cosine: 1.0000 - val_loss: 1056537.6310 - val_mse: 1056538.0000 - val_mae: 852.0111 - val_mape: 12546.9131 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109062.9106 - mse: 109062.9688 - mae: 208.5074 - mape: 32.8549 - cosine: 1.0000 - val_loss: 1057985.3922 - val_mse: 1057986.6250 - val_mae: 855.2921 - val_mape: 12605.9668 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108611.7318 - mse: 108611.6797 - mae: 207.9956 - mape: 32.7525 - cosine: 1.0000 - val_loss: 1066724.4211 - val_mse: 1066723.3750 - val_mae: 865.9310 - val_mape: 12779.4111 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108182.3424 - mse: 108182.4531 - mae: 207.5205 - mape: 32.6498 - cosine: 1.0000 - val_loss: 1005901.2683 - val_mse: 1005901.8750 - val_mae: 827.9938 - val_mape: 12180.3311 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107717.8716 - mse: 107717.9141 - mae: 207.0669 - mape: 32.5926 - cosine: 1.0000 - val_loss: 1032830.4170 - val_mse: 1032829.5625 - val_mae: 848.9573 - val_mape: 12515.7012 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107426.9573 - mse: 107426.7969 - mae: 206.7235 - mape: 32.5074 - cosine: 1.0000 - val_loss: 943699.2192 - val_mse: 943699.8125 - val_mae: 792.7331 - val_mape: 11634.9590 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107019.9640 - mse: 107020.1016 - mae: 206.2720 - mape: 32.4287 - cosine: 1.0000 - val_loss: 1044563.4101 - val_mse: 1044563.3750 - val_mae: 836.9883 - val_mape: 12302.1172 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106698.2084 - mse: 106698.1406 - mae: 205.8599 - mape: 32.3658 - cosine: 1.0000 - val_loss: 1041209.7623 - val_mse: 1041210.0625 - val_mae: 828.4849 - val_mape: 12157.0146 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106344.9824 - mse: 106344.9297 - mae: 205.5242 - mape: 32.3016 - cosine: 1.0000 - val_loss: 956119.0804 - val_mse: 956120.2500 - val_mae: 810.1837 - val_mape: 11923.7295 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106025.7013 - mse: 106025.5234 - mae: 205.0958 - mape: 32.2294 - cosine: 1.0000 - val_loss: 1022679.5497 - val_mse: 1022679.8125 - val_mae: 823.6050 - val_mape: 12093.0488 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105799.6513 - mse: 105799.6484 - mae: 204.8864 - mape: 32.1505 - cosine: 1.0000 - val_loss: 1039718.0376 - val_mse: 1039718.9375 - val_mae: 823.2954 - val_mape: 12072.8809 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105479.0040 - mse: 105479.0234 - mae: 204.4497 - mape: 32.0912 - cosine: 1.0000 - val_loss: 1071011.8532 - val_mse: 1071010.7500 - val_mae: 853.2000 - val_mape: 12547.0840 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105298.0095 - mse: 105298.0547 - mae: 204.2242 - mape: 32.0653 - cosine: 1.0000 - val_loss: 991463.2475 - val_mse: 991463.2500 - val_mae: 825.0203 - val_mape: 12146.0459 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105059.4767 - mse: 105059.4922 - mae: 204.0093 - mape: 32.0569 - cosine: 1.0000 - val_loss: 1019389.2653 - val_mse: 1019389.8125 - val_mae: 834.4952 - val_mape: 12278.2236 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","  6%|▌         | 2/36 [10:49<3:04:58, 326.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 142922.1479 - mse: 142921.9844 - mae: 243.6196 - mape: 39.8923 - cosine: 0.9999 - val_loss: 924481.2454 - val_mse: 924481.3750 - val_mae: 808.1171 - val_mape: 11945.2168 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 121234.7028 - mse: 121234.8359 - mae: 222.4533 - mape: 35.5126 - cosine: 1.0000 - val_loss: 947400.1941 - val_mse: 947399.5625 - val_mae: 807.4454 - val_mape: 11894.4434 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 117846.5747 - mse: 117846.5938 - mae: 218.2584 - mape: 34.5744 - cosine: 1.0000 - val_loss: 1040907.7858 - val_mse: 1040908.0000 - val_mae: 865.3167 - val_mape: 12799.4141 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115539.3636 - mse: 115539.2422 - mae: 215.5686 - mape: 34.0013 - cosine: 1.0000 - val_loss: 936301.8212 - val_mse: 936301.3750 - val_mae: 795.7209 - val_mape: 11702.9668 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 113896.1290 - mse: 113895.9688 - mae: 213.6478 - mape: 33.6570 - cosine: 1.0000 - val_loss: 1078052.1116 - val_mse: 1078052.3750 - val_mae: 860.0341 - val_mape: 12668.1885 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 112701.9517 - mse: 112701.9531 - mae: 212.3348 - mape: 33.4513 - cosine: 1.0000 - val_loss: 973289.4744 - val_mse: 973290.1250 - val_mae: 825.6417 - val_mape: 12173.5547 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111762.5457 - mse: 111762.5156 - mae: 211.2204 - mape: 33.2488 - cosine: 1.0000 - val_loss: 979651.2044 - val_mse: 979650.8750 - val_mae: 827.2028 - val_mape: 12203.3398 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110729.4815 - mse: 110729.4219 - mae: 210.1824 - mape: 33.0751 - cosine: 1.0000 - val_loss: 872514.6524 - val_mse: 872514.5625 - val_mae: 770.2177 - val_mape: 11329.3564 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109902.4758 - mse: 109902.6406 - mae: 209.3031 - mape: 32.9359 - cosine: 1.0000 - val_loss: 1025855.4801 - val_mse: 1025855.5000 - val_mae: 831.8842 - val_mape: 12236.0488 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109441.9476 - mse: 109442.1406 - mae: 208.8591 - mape: 32.8931 - cosine: 1.0000 - val_loss: 1002918.8423 - val_mse: 1002918.1250 - val_mae: 834.1995 - val_mape: 12301.8516 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108873.9033 - mse: 108874.0078 - mae: 208.3327 - mape: 32.7912 - cosine: 1.0000 - val_loss: 984674.8446 - val_mse: 984675.5625 - val_mae: 821.5508 - val_mape: 12099.8184 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108419.4191 - mse: 108419.3203 - mae: 207.9167 - mape: 32.7381 - cosine: 1.0000 - val_loss: 991385.5369 - val_mse: 991386.2500 - val_mae: 819.2022 - val_mape: 12047.9980 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108108.3118 - mse: 108108.0312 - mae: 207.5865 - mape: 32.6683 - cosine: 1.0000 - val_loss: 947143.9061 - val_mse: 947143.6250 - val_mae: 806.1769 - val_mape: 11864.2988 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107768.0891 - mse: 107768.3438 - mae: 207.2927 - mape: 32.6427 - cosine: 1.0000 - val_loss: 969032.2147 - val_mse: 969032.1875 - val_mae: 808.6234 - val_mape: 11886.8232 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107391.9948 - mse: 107391.9141 - mae: 206.8225 - mape: 32.5323 - cosine: 1.0000 - val_loss: 1088855.2774 - val_mse: 1088856.6250 - val_mae: 878.8956 - val_mape: 12982.5381 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107007.4949 - mse: 107007.4219 - mae: 206.3788 - mape: 32.4305 - cosine: 1.0000 - val_loss: 991685.0954 - val_mse: 991685.1875 - val_mae: 812.5273 - val_mape: 11931.6885 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106632.9722 - mse: 106633.0469 - mae: 205.9005 - mape: 32.3516 - cosine: 1.0000 - val_loss: 1046874.6224 - val_mse: 1046874.7500 - val_mae: 850.8612 - val_mape: 12536.0371 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106253.6313 - mse: 106253.5547 - mae: 205.3880 - mape: 32.2483 - cosine: 1.0000 - val_loss: 1004360.6764 - val_mse: 1004361.7500 - val_mae: 837.6695 - val_mape: 12347.7959 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105909.3725 - mse: 105909.5547 - mae: 204.9777 - mape: 32.2049 - cosine: 1.0000 - val_loss: 1115862.0022 - val_mse: 1115861.0000 - val_mae: 867.3387 - val_mape: 12754.4287 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105730.3806 - mse: 105730.5703 - mae: 204.7463 - mape: 32.1600 - cosine: 1.0000 - val_loss: 1086031.6518 - val_mse: 1086032.0000 - val_mae: 848.9921 - val_mape: 12476.8867 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","  8%|▊         | 3/36 [16:10<2:58:36, 324.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 178125.6876 - mse: 178125.4062 - mae: 271.9500 - mape: 44.4495 - cosine: 0.9998 - val_loss: 1002200.0141 - val_mse: 1002199.1875 - val_mae: 840.1122 - val_mape: 12413.7725 - val_cosine: 0.9996\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 134650.2137 - mse: 134650.2031 - mae: 235.6095 - mape: 36.8839 - cosine: 0.9994 - val_loss: 1005629.6496 - val_mse: 1005629.8125 - val_mae: 833.6713 - val_mape: 12288.6777 - val_cosine: 0.9992\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 128420.4925 - mse: 128420.5859 - mae: 229.3119 - mape: 35.7219 - cosine: 0.9991 - val_loss: 1043651.4878 - val_mse: 1043652.1875 - val_mae: 861.3530 - val_mape: 12728.6553 - val_cosine: 0.9994\n","Epoch 4/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 124745.0928 - mse: 124745.1406 - mae: 225.3768 - mape: 35.0952 - cosine: 0.9991 - val_loss: 978495.9092 - val_mse: 978494.8125 - val_mae: 815.0947 - val_mape: 11990.2637 - val_cosine: 0.9989\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 122312.8137 - mse: 122312.9766 - mae: 222.7134 - mape: 34.6619 - cosine: 0.9993 - val_loss: 988830.3655 - val_mse: 988831.8125 - val_mae: 817.5473 - val_mape: 12022.2920 - val_cosine: 0.9994\n","Epoch 6/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 120723.5259 - mse: 120723.5078 - mae: 220.7538 - mape: 34.2915 - cosine: 0.9997 - val_loss: 1049798.4691 - val_mse: 1049798.6250 - val_mae: 850.3562 - val_mape: 12530.4502 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 119626.0314 - mse: 119626.2031 - mae: 219.4645 - mape: 34.1660 - cosine: 1.0000 - val_loss: 1073078.9445 - val_mse: 1073079.3750 - val_mae: 869.6022 - val_mape: 12837.2119 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 118678.4436 - mse: 118678.5000 - mae: 218.3167 - mape: 34.0493 - cosine: 1.0000 - val_loss: 1065836.1352 - val_mse: 1065835.0000 - val_mae: 859.8475 - val_mape: 12676.6738 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 117923.2344 - mse: 117923.0234 - mae: 217.5709 - mape: 34.0856 - cosine: 1.0000 - val_loss: 1054081.3602 - val_mse: 1054081.1250 - val_mae: 862.1115 - val_mape: 12726.6416 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 117185.7926 - mse: 117185.8516 - mae: 216.8566 - mape: 34.0917 - cosine: 1.0000 - val_loss: 1069206.5709 - val_mse: 1069206.5000 - val_mae: 868.1939 - val_mape: 12817.2598 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 116472.2746 - mse: 116472.4141 - mae: 216.1586 - mape: 34.0590 - cosine: 1.0000 - val_loss: 992157.4401 - val_mse: 992156.1250 - val_mae: 824.0367 - val_mape: 12134.8555 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 115773.5109 - mse: 115773.4688 - mae: 215.5529 - mape: 34.0454 - cosine: 1.0000 - val_loss: 943081.0839 - val_mse: 943080.8750 - val_mae: 806.8539 - val_mape: 11896.8594 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115226.6119 - mse: 115226.6875 - mae: 214.9410 - mape: 33.9620 - cosine: 1.0000 - val_loss: 1012018.2878 - val_mse: 1012017.8750 - val_mae: 833.2845 - val_mape: 12270.7051 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 114765.0078 - mse: 114765.2656 - mae: 214.4996 - mape: 33.8979 - cosine: 1.0000 - val_loss: 1012714.0750 - val_mse: 1012714.3125 - val_mae: 832.2085 - val_mape: 12254.0771 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 114290.5685 - mse: 114290.5625 - mae: 213.9866 - mape: 33.8167 - cosine: 1.0000 - val_loss: 965877.7343 - val_mse: 965877.2500 - val_mae: 796.0869 - val_mape: 11687.5215 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 113948.9080 - mse: 113948.8516 - mae: 213.5881 - mape: 33.7534 - cosine: 1.0000 - val_loss: 1011658.0495 - val_mse: 1011658.5000 - val_mae: 832.2504 - val_mape: 12259.6104 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 113695.8002 - mse: 113695.7188 - mae: 213.3650 - mape: 33.7133 - cosine: 1.0000 - val_loss: 1030702.7275 - val_mse: 1030703.8750 - val_mae: 839.4709 - val_mape: 12363.8545 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 113454.4126 - mse: 113454.4219 - mae: 213.0907 - mape: 33.6686 - cosine: 1.0000 - val_loss: 1034284.2367 - val_mse: 1034284.3125 - val_mae: 848.9838 - val_mape: 12519.8262 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 113165.6012 - mse: 113165.5703 - mae: 212.8076 - mape: 33.5974 - cosine: 1.0000 - val_loss: 1063476.1137 - val_mse: 1063475.5000 - val_mae: 868.2928 - val_mape: 12820.9941 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 112913.3717 - mse: 112913.4062 - mae: 212.5102 - mape: 33.5346 - cosine: 1.0000 - val_loss: 950755.4145 - val_mse: 950755.0625 - val_mae: 809.6039 - val_mape: 11926.1777 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 11%|█         | 4/36 [21:22<2:51:04, 320.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 155886.9021 - mse: 155886.8750 - mae: 253.9816 - mape: 41.1762 - cosine: 0.9999 - val_loss: 1052062.8655 - val_mse: 1052062.3750 - val_mae: 848.6847 - val_mape: 12509.7900 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 125164.9326 - mse: 125165.0312 - mae: 226.6026 - mape: 35.5905 - cosine: 1.0000 - val_loss: 1001229.0930 - val_mse: 1001229.4375 - val_mae: 838.8662 - val_mape: 12384.3564 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 121962.1774 - mse: 121962.2109 - mae: 222.8924 - mape: 35.0076 - cosine: 1.0000 - val_loss: 1101480.4531 - val_mse: 1101480.3750 - val_mae: 876.7535 - val_mape: 12934.5820 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 119769.0835 - mse: 119769.0312 - mae: 220.2178 - mape: 34.5645 - cosine: 1.0000 - val_loss: 985728.8022 - val_mse: 985728.6250 - val_mae: 816.5417 - val_mape: 12012.6279 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 117811.5598 - mse: 117811.5703 - mae: 217.7599 - mape: 34.1584 - cosine: 1.0000 - val_loss: 977555.1268 - val_mse: 977555.0625 - val_mae: 817.5448 - val_mape: 12041.4277 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 115945.0162 - mse: 115945.0078 - mae: 215.6672 - mape: 33.8800 - cosine: 1.0000 - val_loss: 1033197.5608 - val_mse: 1033197.5625 - val_mae: 839.5142 - val_mape: 12358.5273 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 114377.1991 - mse: 114377.1797 - mae: 214.0914 - mape: 33.6770 - cosine: 1.0000 - val_loss: 1059429.1488 - val_mse: 1059429.1250 - val_mae: 854.4710 - val_mape: 12592.2197 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 113004.5575 - mse: 113004.6250 - mae: 212.6195 - mape: 33.5325 - cosine: 1.0000 - val_loss: 952842.4182 - val_mse: 952841.8125 - val_mae: 805.4322 - val_mape: 11851.7812 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 111731.6299 - mse: 111731.7266 - mae: 211.4304 - mape: 33.3936 - cosine: 1.0000 - val_loss: 1068380.1156 - val_mse: 1068379.5000 - val_mae: 862.6699 - val_mape: 12723.3311 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 110740.5738 - mse: 110740.6016 - mae: 210.4036 - mape: 33.2611 - cosine: 1.0000 - val_loss: 989463.8823 - val_mse: 989464.4375 - val_mae: 823.3896 - val_mape: 12127.8975 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 110005.1841 - mse: 110005.0234 - mae: 209.7810 - mape: 33.1860 - cosine: 1.0000 - val_loss: 1061689.2565 - val_mse: 1061688.3750 - val_mae: 858.7240 - val_mape: 12661.4121 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 109554.8725 - mse: 109554.8516 - mae: 209.2838 - mape: 33.1208 - cosine: 1.0000 - val_loss: 1006307.1812 - val_mse: 1006307.5000 - val_mae: 823.2535 - val_mape: 12099.9922 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 108998.2354 - mse: 108998.0312 - mae: 208.7451 - mape: 33.0367 - cosine: 1.0000 - val_loss: 1049271.7259 - val_mse: 1049272.2500 - val_mae: 841.0452 - val_mape: 12364.1338 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 108633.7488 - mse: 108633.9609 - mae: 208.2449 - mape: 32.9281 - cosine: 1.0000 - val_loss: 1067043.2326 - val_mse: 1067043.8750 - val_mae: 857.4559 - val_mape: 12631.9473 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 108198.4214 - mse: 108198.4766 - mae: 207.9640 - mape: 32.9187 - cosine: 1.0000 - val_loss: 1082434.9079 - val_mse: 1082434.8750 - val_mae: 865.2909 - val_mape: 12748.8994 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 107927.4084 - mse: 107927.3359 - mae: 207.5811 - mape: 32.8429 - cosine: 1.0000 - val_loss: 981774.0012 - val_mse: 981773.8125 - val_mae: 817.3097 - val_mape: 12026.7754 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 107513.2004 - mse: 107513.2344 - mae: 207.3129 - mape: 32.8198 - cosine: 1.0000 - val_loss: 1038939.0545 - val_mse: 1038939.1875 - val_mae: 843.6083 - val_mape: 12418.1582 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 107363.0621 - mse: 107363.1484 - mae: 207.0807 - mape: 32.7789 - cosine: 1.0000 - val_loss: 911880.7696 - val_mse: 911880.5000 - val_mae: 758.4070 - val_mape: 11102.2812 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 106922.2470 - mse: 106922.2422 - mae: 206.5451 - mape: 32.7247 - cosine: 1.0000 - val_loss: 986614.1908 - val_mse: 986614.5625 - val_mae: 814.5486 - val_mape: 11970.7295 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 106614.9582 - mse: 106615.2109 - mae: 206.3169 - mape: 32.6681 - cosine: 1.0000 - val_loss: 1084506.2676 - val_mse: 1084505.8750 - val_mae: 871.7538 - val_mape: 12854.4648 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 14%|█▍        | 5/36 [24:22<2:23:55, 278.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 143193.6765 - mse: 143193.5000 - mae: 245.2507 - mape: 40.3356 - cosine: 1.0000 - val_loss: 926625.5623 - val_mse: 926626.2500 - val_mae: 786.1854 - val_mape: 11567.6465 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 122695.3301 - mse: 122695.2969 - mae: 223.9027 - mape: 35.6869 - cosine: 1.0000 - val_loss: 1026274.1259 - val_mse: 1026274.0625 - val_mae: 843.3527 - val_mape: 12433.8701 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 119316.5759 - mse: 119316.8438 - mae: 219.4961 - mape: 34.6357 - cosine: 1.0000 - val_loss: 1000335.7738 - val_mse: 1000336.3125 - val_mae: 833.7836 - val_mape: 12292.5859 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 116783.4770 - mse: 116783.3594 - mae: 216.6401 - mape: 34.0344 - cosine: 1.0000 - val_loss: 941899.2306 - val_mse: 941898.7500 - val_mae: 816.0561 - val_mape: 12052.6631 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 114397.4096 - mse: 114397.6172 - mae: 214.2074 - mape: 33.7254 - cosine: 1.0000 - val_loss: 976462.3386 - val_mse: 976462.3750 - val_mae: 827.5935 - val_mape: 12213.8809 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 112697.8541 - mse: 112697.8594 - mae: 212.4120 - mape: 33.4535 - cosine: 1.0000 - val_loss: 1107172.5165 - val_mse: 1107171.7500 - val_mae: 878.6926 - val_mape: 12960.0430 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111198.5816 - mse: 111198.3516 - mae: 210.6125 - mape: 33.0961 - cosine: 1.0000 - val_loss: 1021528.2902 - val_mse: 1021529.0000 - val_mae: 841.9202 - val_mape: 12415.9971 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110115.9336 - mse: 110115.8984 - mae: 209.5334 - mape: 32.9609 - cosine: 1.0000 - val_loss: 1058110.5306 - val_mse: 1058110.5000 - val_mae: 851.8832 - val_mape: 12544.1045 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109196.7612 - mse: 109196.9766 - mae: 208.5396 - mape: 32.8310 - cosine: 1.0000 - val_loss: 1081419.3560 - val_mse: 1081420.1250 - val_mae: 866.0872 - val_mape: 12765.6562 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108622.0311 - mse: 108622.4141 - mae: 207.8428 - mape: 32.6905 - cosine: 1.0000 - val_loss: 1010236.4619 - val_mse: 1010237.0625 - val_mae: 850.4410 - val_mape: 12568.1348 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108011.1341 - mse: 108011.1719 - mae: 207.1758 - mape: 32.6039 - cosine: 1.0000 - val_loss: 955491.3802 - val_mse: 955489.5625 - val_mae: 812.6006 - val_mape: 11961.6992 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107510.0386 - mse: 107510.1641 - mae: 206.6994 - mape: 32.4984 - cosine: 1.0000 - val_loss: 1025634.5794 - val_mse: 1025634.0000 - val_mae: 832.0986 - val_mape: 12231.5078 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107137.0136 - mse: 107136.7500 - mae: 206.2768 - mape: 32.4445 - cosine: 1.0000 - val_loss: 1007959.0448 - val_mse: 1007959.0000 - val_mae: 828.7768 - val_mape: 12198.0791 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106681.9017 - mse: 106681.7109 - mae: 205.8157 - mape: 32.4019 - cosine: 1.0000 - val_loss: 999922.6905 - val_mse: 999922.5625 - val_mae: 818.1104 - val_mape: 12015.0898 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106362.3002 - mse: 106362.5625 - mae: 205.4295 - mape: 32.3332 - cosine: 1.0000 - val_loss: 998476.5703 - val_mse: 998477.5000 - val_mae: 821.6208 - val_mape: 12074.7793 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 106053.6602 - mse: 106053.5234 - mae: 205.1338 - mape: 32.2869 - cosine: 1.0000 - val_loss: 1025553.7284 - val_mse: 1025553.3125 - val_mae: 850.1616 - val_mape: 12547.5371 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105743.1696 - mse: 105742.8828 - mae: 204.7808 - mape: 32.2359 - cosine: 1.0000 - val_loss: 1036742.4153 - val_mse: 1036741.7500 - val_mae: 844.3903 - val_mape: 12428.6592 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105453.5395 - mse: 105453.5703 - mae: 204.3489 - mape: 32.1539 - cosine: 1.0000 - val_loss: 1080161.9381 - val_mse: 1080162.2500 - val_mae: 863.9652 - val_mape: 12724.8701 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105119.4154 - mse: 105119.6797 - mae: 204.0056 - mape: 32.0731 - cosine: 1.0000 - val_loss: 1046574.8602 - val_mse: 1046574.5625 - val_mae: 845.9998 - val_mape: 12450.1318 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 104953.6248 - mse: 104953.9062 - mae: 203.8395 - mape: 32.0602 - cosine: 1.0000 - val_loss: 1132128.3861 - val_mse: 1132128.7500 - val_mae: 875.9540 - val_mape: 12888.2959 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 17%|█▋        | 6/36 [29:11<2:20:49, 281.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 141013.8868 - mse: 141013.6719 - mae: 241.0320 - mape: 38.7535 - cosine: 1.0000 - val_loss: 971777.0864 - val_mse: 971776.6250 - val_mae: 824.6088 - val_mape: 12173.7959 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 118153.9323 - mse: 118154.0781 - mae: 218.7638 - mape: 34.5112 - cosine: 1.0000 - val_loss: 1025208.2294 - val_mse: 1025208.6250 - val_mae: 833.4926 - val_mape: 12266.8271 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 115415.6376 - mse: 115415.5938 - mae: 215.6303 - mape: 34.0720 - cosine: 1.0000 - val_loss: 1047093.3048 - val_mse: 1047093.3125 - val_mae: 856.9590 - val_mape: 12654.3994 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113804.4352 - mse: 113804.3672 - mae: 213.9139 - mape: 33.8736 - cosine: 1.0000 - val_loss: 944492.7341 - val_mse: 944491.9375 - val_mae: 808.7402 - val_mape: 11926.3857 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 112617.7370 - mse: 112617.7812 - mae: 212.7723 - mape: 33.7550 - cosine: 1.0000 - val_loss: 965108.7364 - val_mse: 965109.5000 - val_mae: 804.9170 - val_mape: 11832.3242 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 111723.7077 - mse: 111723.5547 - mae: 211.8661 - mape: 33.6193 - cosine: 1.0000 - val_loss: 969022.1774 - val_mse: 969023.6875 - val_mae: 805.4238 - val_mape: 11846.4043 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110851.9816 - mse: 110852.1406 - mae: 210.9617 - mape: 33.4633 - cosine: 1.0000 - val_loss: 1075113.0983 - val_mse: 1075113.7500 - val_mae: 860.1801 - val_mape: 12671.2480 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110023.1905 - mse: 110023.0469 - mae: 209.9690 - mape: 33.1608 - cosine: 1.0000 - val_loss: 927609.2482 - val_mse: 927608.8750 - val_mae: 793.1104 - val_mape: 11668.7773 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109116.5667 - mse: 109116.6484 - mae: 208.9283 - mape: 32.9237 - cosine: 1.0000 - val_loss: 1028150.2779 - val_mse: 1028150.3750 - val_mae: 834.8534 - val_mape: 12277.2559 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108496.4099 - mse: 108496.4844 - mae: 208.1638 - mape: 32.8119 - cosine: 1.0000 - val_loss: 1029064.3328 - val_mse: 1029064.6875 - val_mae: 836.3305 - val_mape: 12304.9248 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108013.5496 - mse: 108013.5547 - mae: 207.6334 - mape: 32.7198 - cosine: 1.0000 - val_loss: 1050368.7666 - val_mse: 1050370.1250 - val_mae: 843.1865 - val_mape: 12399.3525 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 107707.6617 - mse: 107707.5781 - mae: 207.2600 - mape: 32.6803 - cosine: 1.0000 - val_loss: 981874.1194 - val_mse: 981874.7500 - val_mae: 809.2228 - val_mape: 11889.1533 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 107241.7967 - mse: 107241.7266 - mae: 206.7636 - mape: 32.5864 - cosine: 1.0000 - val_loss: 1105386.8212 - val_mse: 1105387.3750 - val_mae: 874.5840 - val_mape: 12880.8311 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106988.9727 - mse: 106989.0938 - mae: 206.3703 - mape: 32.5132 - cosine: 1.0000 - val_loss: 949792.1963 - val_mse: 949792.6875 - val_mae: 795.4855 - val_mape: 11682.6553 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 106643.0368 - mse: 106643.0859 - mae: 205.9205 - mape: 32.4233 - cosine: 1.0000 - val_loss: 1049210.3318 - val_mse: 1049210.2500 - val_mae: 833.5688 - val_mape: 12239.4512 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 106374.1311 - mse: 106374.2266 - mae: 205.6059 - mape: 32.4048 - cosine: 1.0000 - val_loss: 982826.7485 - val_mse: 982825.7500 - val_mae: 827.4402 - val_mape: 12196.0430 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106126.9805 - mse: 106127.0312 - mae: 205.2581 - mape: 32.3373 - cosine: 1.0000 - val_loss: 1021163.1047 - val_mse: 1021163.3125 - val_mae: 845.6247 - val_mape: 12465.0605 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105723.7902 - mse: 105723.6797 - mae: 204.7849 - mape: 32.2545 - cosine: 1.0000 - val_loss: 995513.0322 - val_mse: 995511.8125 - val_mae: 814.3999 - val_mape: 11961.0693 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105398.1059 - mse: 105398.1719 - mae: 204.3768 - mape: 32.1842 - cosine: 1.0000 - val_loss: 977828.3573 - val_mse: 977828.0625 - val_mae: 824.5007 - val_mape: 12143.8779 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105175.8462 - mse: 105175.5781 - mae: 204.1311 - mape: 32.1256 - cosine: 1.0000 - val_loss: 1052544.4807 - val_mse: 1052543.3750 - val_mae: 847.6388 - val_mape: 12469.7139 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 19%|█▉        | 7/36 [34:08<2:18:24, 286.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 137725.6503 - mse: 137725.5312 - mae: 240.1918 - mape: 39.1992 - cosine: 0.9999 - val_loss: 925032.2623 - val_mse: 925031.3750 - val_mae: 808.8374 - val_mape: 11956.7334 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 122050.4003 - mse: 122050.6094 - mae: 223.2690 - mape: 35.4999 - cosine: 1.0000 - val_loss: 1003355.9618 - val_mse: 1003354.0625 - val_mae: 824.9462 - val_mape: 12140.9570 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 117602.8065 - mse: 117602.6172 - mae: 218.2133 - mape: 34.5812 - cosine: 1.0000 - val_loss: 872486.9965 - val_mse: 872486.7500 - val_mae: 749.4097 - val_mape: 10978.6572 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 114533.6022 - mse: 114533.9375 - mae: 215.2534 - mape: 34.1504 - cosine: 1.0000 - val_loss: 1014082.9074 - val_mse: 1014084.1875 - val_mae: 845.2825 - val_mape: 12477.4639 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 113068.2168 - mse: 113068.2344 - mae: 213.8069 - mape: 33.9806 - cosine: 1.0000 - val_loss: 1027002.2766 - val_mse: 1027003.0000 - val_mae: 840.4720 - val_mape: 12391.1611 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 111707.1931 - mse: 111707.1250 - mae: 212.1837 - mape: 33.6515 - cosine: 1.0000 - val_loss: 995469.6170 - val_mse: 995470.6250 - val_mae: 820.4217 - val_mape: 12072.6494 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 110851.7965 - mse: 110851.7188 - mae: 211.1689 - mape: 33.4294 - cosine: 1.0000 - val_loss: 989950.8363 - val_mse: 989949.8750 - val_mae: 809.1734 - val_mape: 11876.5547 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 109929.6441 - mse: 109929.8281 - mae: 209.9107 - mape: 33.1671 - cosine: 1.0000 - val_loss: 981440.0589 - val_mse: 981439.3750 - val_mae: 822.8908 - val_mape: 12123.2354 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 108870.4271 - mse: 108870.7578 - mae: 208.5180 - mape: 32.9071 - cosine: 1.0000 - val_loss: 1107178.0554 - val_mse: 1107178.2500 - val_mae: 871.8859 - val_mape: 12841.8174 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 108332.5695 - mse: 108332.6094 - mae: 207.7710 - mape: 32.7132 - cosine: 1.0000 - val_loss: 871837.1169 - val_mse: 871836.1875 - val_mae: 759.0793 - val_mape: 11151.0088 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 107816.9330 - mse: 107817.0078 - mae: 207.0686 - mape: 32.5461 - cosine: 1.0000 - val_loss: 1048183.0963 - val_mse: 1048182.8750 - val_mae: 844.0537 - val_mape: 12413.0732 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 107311.9608 - mse: 107312.2500 - mae: 206.4596 - mape: 32.4197 - cosine: 1.0000 - val_loss: 1083099.5004 - val_mse: 1083099.6250 - val_mae: 861.2563 - val_mape: 12678.6094 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 106873.9825 - mse: 106873.8438 - mae: 205.8856 - mape: 32.2886 - cosine: 1.0000 - val_loss: 1080929.5143 - val_mse: 1080930.0000 - val_mae: 870.9589 - val_mape: 12850.0840 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 106550.9243 - mse: 106551.0156 - mae: 205.5058 - mape: 32.2443 - cosine: 1.0000 - val_loss: 1114407.2497 - val_mse: 1114406.8750 - val_mae: 872.7695 - val_mape: 12843.7578 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 106151.1373 - mse: 106150.7031 - mae: 204.9605 - mape: 32.1271 - cosine: 1.0000 - val_loss: 1054374.5990 - val_mse: 1054375.0000 - val_mae: 851.0612 - val_mape: 12535.3555 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 105727.3494 - mse: 105727.0000 - mae: 204.2682 - mape: 32.0019 - cosine: 1.0000 - val_loss: 944376.6312 - val_mse: 944376.1250 - val_mae: 799.0886 - val_mape: 11749.7578 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 105329.5633 - mse: 105329.6484 - mae: 203.7446 - mape: 31.9021 - cosine: 1.0000 - val_loss: 1034341.4637 - val_mse: 1034340.9375 - val_mae: 839.2751 - val_mape: 12344.5107 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 104880.4974 - mse: 104880.2031 - mae: 203.2367 - mape: 31.7953 - cosine: 1.0000 - val_loss: 924516.9164 - val_mse: 924516.2500 - val_mae: 787.6885 - val_mape: 11564.7930 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 104731.8602 - mse: 104732.0469 - mae: 202.9069 - mape: 31.7581 - cosine: 1.0000 - val_loss: 992646.1395 - val_mse: 992645.0625 - val_mae: 811.1870 - val_mape: 11910.0879 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 104489.0195 - mse: 104489.0547 - mae: 202.6287 - mape: 31.7081 - cosine: 1.0000 - val_loss: 1069523.8734 - val_mse: 1069523.0000 - val_mae: 846.1141 - val_mape: 12426.4111 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 22%|██▏       | 8/36 [42:50<2:46:36, 357.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 163964.8973 - mse: 163964.8750 - mae: 261.6874 - mape: 43.1227 - cosine: 1.0000 - val_loss: 966981.1265 - val_mse: 966981.5625 - val_mae: 834.7775 - val_mape: 12362.7539 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 131279.8326 - mse: 131279.7656 - mae: 232.6765 - mape: 36.6795 - cosine: 1.0000 - val_loss: 1056312.2823 - val_mse: 1056311.7500 - val_mae: 867.5624 - val_mape: 12831.8027 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 123677.0931 - mse: 123677.2188 - mae: 224.7349 - mape: 35.6961 - cosine: 1.0000 - val_loss: 969648.8695 - val_mse: 969648.8125 - val_mae: 819.5699 - val_mape: 12083.7207 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 120733.9048 - mse: 120733.8438 - mae: 220.9684 - mape: 34.9105 - cosine: 1.0000 - val_loss: 983690.6414 - val_mse: 983689.3750 - val_mae: 823.8028 - val_mape: 12140.8203 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 118239.6631 - mse: 118239.7500 - mae: 217.9718 - mape: 34.2806 - cosine: 1.0000 - val_loss: 1038439.8590 - val_mse: 1038439.5625 - val_mae: 858.6486 - val_mape: 12688.3506 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 115918.4184 - mse: 115918.4688 - mae: 215.4223 - mape: 33.7993 - cosine: 1.0000 - val_loss: 1059068.3451 - val_mse: 1059068.1250 - val_mae: 843.7796 - val_mape: 12407.8633 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 114476.0467 - mse: 114476.2266 - mae: 213.8240 - mape: 33.4898 - cosine: 1.0000 - val_loss: 976400.1206 - val_mse: 976400.0000 - val_mae: 803.1922 - val_mape: 11792.5352 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113244.7142 - mse: 113244.6953 - mae: 212.5206 - mape: 33.2787 - cosine: 1.0000 - val_loss: 988187.4912 - val_mse: 988186.8750 - val_mae: 826.7059 - val_mape: 12178.3838 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 112303.9371 - mse: 112303.7266 - mae: 211.5649 - mape: 33.1166 - cosine: 1.0000 - val_loss: 936355.4905 - val_mse: 936355.3125 - val_mae: 794.1445 - val_mape: 11677.8857 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111322.6402 - mse: 111322.4453 - mae: 210.5113 - mape: 32.9541 - cosine: 1.0000 - val_loss: 1015617.1003 - val_mse: 1015617.1250 - val_mae: 844.0124 - val_mape: 12450.7178 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110451.6268 - mse: 110451.7031 - mae: 209.5738 - mape: 32.8023 - cosine: 1.0000 - val_loss: 1046299.6801 - val_mse: 1046299.5000 - val_mae: 856.4539 - val_mape: 12626.3125 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109684.8350 - mse: 109684.8125 - mae: 208.8110 - mape: 32.6812 - cosine: 1.0000 - val_loss: 994964.7517 - val_mse: 994965.3125 - val_mae: 830.8887 - val_mape: 12242.8066 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 108980.1003 - mse: 108979.9766 - mae: 208.1079 - mape: 32.6039 - cosine: 1.0000 - val_loss: 924570.9484 - val_mse: 924571.1250 - val_mae: 782.5762 - val_mape: 11490.7500 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108469.2344 - mse: 108469.2266 - mae: 207.5805 - mape: 32.5506 - cosine: 1.0000 - val_loss: 1029809.3503 - val_mse: 1029809.2500 - val_mae: 832.4295 - val_mape: 12230.0605 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108071.7106 - mse: 108071.8516 - mae: 207.1132 - mape: 32.4820 - cosine: 1.0000 - val_loss: 987336.9631 - val_mse: 987336.4375 - val_mae: 816.2183 - val_mape: 12004.3564 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107576.9132 - mse: 107576.7734 - mae: 206.5836 - mape: 32.3880 - cosine: 1.0000 - val_loss: 1025606.1864 - val_mse: 1025607.0625 - val_mae: 826.2969 - val_mape: 12128.4502 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 107168.3414 - mse: 107168.4453 - mae: 206.1714 - mape: 32.3279 - cosine: 1.0000 - val_loss: 1004837.3536 - val_mse: 1004838.0000 - val_mae: 834.2594 - val_mape: 12292.8447 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106858.1241 - mse: 106857.9922 - mae: 205.8622 - mape: 32.2870 - cosine: 1.0000 - val_loss: 1064289.2125 - val_mse: 1064288.2500 - val_mae: 840.5315 - val_mape: 12344.2725 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106657.9940 - mse: 106658.0312 - mae: 205.5094 - mape: 32.2093 - cosine: 1.0000 - val_loss: 1087631.2318 - val_mse: 1087630.6250 - val_mae: 861.7769 - val_mape: 12683.8672 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106314.9026 - mse: 106314.6641 - mae: 205.1642 - mape: 32.1574 - cosine: 1.0000 - val_loss: 1090725.7842 - val_mse: 1090725.8750 - val_mae: 862.5463 - val_mape: 12695.9238 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 25%|██▌       | 9/36 [47:37<2:31:14, 336.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6284 - mse: 1137031.5000 - mae: 838.9208 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 2/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6288 - mse: 1137035.6250 - mae: 838.9216 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 3/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6287 - mse: 1137034.3750 - mae: 838.9203 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 4/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6284 - mse: 1137034.3750 - mae: 838.9219 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 5/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6279 - mse: 1137035.5000 - mae: 838.9191 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 6/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6280 - mse: 1137033.1250 - mae: 838.9219 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 7/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6292 - mse: 1137038.2500 - mae: 838.9205 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 8/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6281 - mse: 1137032.6250 - mae: 838.9187 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 9/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 1137034.6284 - mse: 1137034.8750 - mae: 838.9213 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 10/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6286 - mse: 1137030.8750 - mae: 838.9203 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 11/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6291 - mse: 1137037.2500 - mae: 838.9183 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 12/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6285 - mse: 1137036.1250 - mae: 838.9221 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 13/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6283 - mse: 1137037.0000 - mae: 838.9194 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 14/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 1137034.6288 - mse: 1137032.7500 - mae: 838.9186 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 15/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6288 - mse: 1137038.5000 - mae: 838.9174 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 16/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 1137034.6275 - mse: 1137032.8750 - mae: 838.9207 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 17/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6280 - mse: 1137032.0000 - mae: 838.9191 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 18/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6284 - mse: 1137035.6250 - mae: 838.9204 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 19/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 1137034.6293 - mse: 1137031.3750 - mae: 838.9201 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 20/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 1137034.6285 - mse: 1137034.3750 - mae: 838.9221 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4965 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 28%|██▊       | 10/36 [56:06<2:48:04, 387.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 150414.1571 - mse: 150414.2969 - mae: 249.6013 - mape: 41.1574 - cosine: 0.9999 - val_loss: 1008350.9073 - val_mse: 1008350.0625 - val_mae: 829.8297 - val_mape: 12236.4561 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 124100.0576 - mse: 124100.0703 - mae: 225.0663 - mape: 35.7715 - cosine: 1.0000 - val_loss: 1043899.4242 - val_mse: 1043899.0625 - val_mae: 850.2145 - val_mape: 12535.8350 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 120847.5246 - mse: 120847.6406 - mae: 220.9538 - mape: 34.7743 - cosine: 1.0000 - val_loss: 977674.1460 - val_mse: 977674.3750 - val_mae: 830.9604 - val_mape: 12269.9629 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 119398.7088 - mse: 119398.6250 - mae: 219.1582 - mape: 34.4133 - cosine: 1.0000 - val_loss: 1061575.0731 - val_mse: 1061575.6250 - val_mae: 876.3781 - val_mape: 12969.8262 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 118325.7997 - mse: 118325.8125 - mae: 217.8753 - mape: 34.2253 - cosine: 1.0000 - val_loss: 1097816.2180 - val_mse: 1097816.5000 - val_mae: 875.1352 - val_mape: 12912.6787 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 117500.3544 - mse: 117500.3984 - mae: 216.9210 - mape: 34.1087 - cosine: 1.0000 - val_loss: 1088711.1492 - val_mse: 1088711.6250 - val_mae: 883.5995 - val_mape: 13065.8623 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 116748.8370 - mse: 116748.8359 - mae: 215.9973 - mape: 33.9615 - cosine: 1.0000 - val_loss: 1007948.0223 - val_mse: 1007948.0000 - val_mae: 829.1222 - val_mape: 12209.7148 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 115663.8366 - mse: 115663.8828 - mae: 214.7166 - mape: 33.7562 - cosine: 1.0000 - val_loss: 1016049.3378 - val_mse: 1016048.6250 - val_mae: 832.3309 - val_mape: 12251.9814 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 114758.5794 - mse: 114758.3984 - mae: 213.6174 - mape: 33.5490 - cosine: 1.0000 - val_loss: 994500.6807 - val_mse: 994500.3750 - val_mae: 829.7315 - val_mape: 12224.5215 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113849.1434 - mse: 113849.2266 - mae: 212.7129 - mape: 33.4691 - cosine: 1.0000 - val_loss: 1017285.9507 - val_mse: 1017285.6250 - val_mae: 826.3962 - val_mape: 12139.4512 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113016.6593 - mse: 113016.7656 - mae: 211.9292 - mape: 33.3386 - cosine: 1.0000 - val_loss: 1113813.7299 - val_mse: 1113813.0000 - val_mae: 875.8099 - val_mape: 12901.6436 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 112184.3710 - mse: 112184.0938 - mae: 211.1526 - mape: 33.2600 - cosine: 1.0000 - val_loss: 1041934.7985 - val_mse: 1041933.9375 - val_mae: 842.6017 - val_mape: 12400.2207 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 111394.7847 - mse: 111394.8750 - mae: 210.4472 - mape: 33.1627 - cosine: 1.0000 - val_loss: 1026760.3918 - val_mse: 1026759.7500 - val_mae: 839.9191 - val_mape: 12368.1387 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110465.1590 - mse: 110465.2109 - mae: 209.5522 - mape: 33.0106 - cosine: 1.0000 - val_loss: 1029553.1524 - val_mse: 1029553.7500 - val_mae: 826.2553 - val_mape: 12136.2266 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109711.0863 - mse: 109710.7344 - mae: 208.8727 - mape: 32.9059 - cosine: 1.0000 - val_loss: 1027292.5334 - val_mse: 1027294.0000 - val_mae: 836.2740 - val_mape: 12302.0732 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108991.1948 - mse: 108990.9922 - mae: 208.2100 - mape: 32.7814 - cosine: 1.0000 - val_loss: 1019321.9250 - val_mse: 1019321.5000 - val_mae: 829.7332 - val_mape: 12205.0234 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108325.3822 - mse: 108325.4453 - mae: 207.5091 - mape: 32.6532 - cosine: 1.0000 - val_loss: 1007945.3003 - val_mse: 1007945.2500 - val_mae: 832.2579 - val_mape: 12251.1826 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107870.6485 - mse: 107870.6562 - mae: 206.9565 - mape: 32.5105 - cosine: 1.0000 - val_loss: 927141.4825 - val_mse: 927142.0625 - val_mae: 784.8369 - val_mape: 11531.3096 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107367.3220 - mse: 107367.5078 - mae: 206.4496 - mape: 32.3937 - cosine: 1.0000 - val_loss: 990221.2007 - val_mse: 990220.7500 - val_mae: 828.8007 - val_mape: 12209.0508 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107050.2918 - mse: 107050.3125 - mae: 206.0273 - mape: 32.2997 - cosine: 1.0000 - val_loss: 999217.4713 - val_mse: 999217.5625 - val_mae: 836.3937 - val_mape: 12335.9492 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 31%|███       | 11/36 [1:00:52<2:28:54, 357.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 153261.0107 - mse: 153260.9844 - mae: 252.5053 - mape: 41.7353 - cosine: 0.9998 - val_loss: 1105693.5214 - val_mse: 1105693.8750 - val_mae: 886.3088 - val_mape: 13111.9170 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 123927.7508 - mse: 123927.8438 - mae: 225.3607 - mape: 35.7624 - cosine: 1.0000 - val_loss: 1035005.9984 - val_mse: 1035004.9375 - val_mae: 843.9377 - val_mape: 12435.8789 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 120442.9554 - mse: 120442.9375 - mae: 220.8990 - mape: 34.8856 - cosine: 1.0000 - val_loss: 1036435.1771 - val_mse: 1036435.8750 - val_mae: 836.4653 - val_mape: 12302.4248 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 118824.1035 - mse: 118824.1562 - mae: 218.8925 - mape: 34.6205 - cosine: 1.0000 - val_loss: 984265.2452 - val_mse: 984264.3125 - val_mae: 819.8016 - val_mape: 12072.8682 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 117276.1045 - mse: 117276.2109 - mae: 217.1069 - mape: 34.3196 - cosine: 1.0000 - val_loss: 1076386.8656 - val_mse: 1076386.5000 - val_mae: 853.7418 - val_mape: 12563.4922 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 115722.0443 - mse: 115722.1094 - mae: 215.5462 - mape: 34.0948 - cosine: 1.0000 - val_loss: 1044982.7500 - val_mse: 1044982.8750 - val_mae: 862.4212 - val_mape: 12745.3555 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 114317.2921 - mse: 114317.1484 - mae: 214.0866 - mape: 33.8929 - cosine: 1.0000 - val_loss: 978341.6109 - val_mse: 978340.6875 - val_mae: 811.1229 - val_mape: 11922.8311 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 113048.6647 - mse: 113048.7422 - mae: 212.8207 - mape: 33.7207 - cosine: 1.0000 - val_loss: 1036063.5508 - val_mse: 1036063.7500 - val_mae: 852.0921 - val_mape: 12567.2471 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 111975.1447 - mse: 111975.1797 - mae: 211.7446 - mape: 33.5825 - cosine: 1.0000 - val_loss: 1034930.3218 - val_mse: 1034930.3750 - val_mae: 842.6030 - val_mape: 12409.3438 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 111128.4251 - mse: 111128.3359 - mae: 211.0737 - mape: 33.5113 - cosine: 1.0000 - val_loss: 1018421.2450 - val_mse: 1018421.0625 - val_mae: 833.3367 - val_mape: 12264.3867 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110448.0547 - mse: 110448.0391 - mae: 210.1911 - mape: 33.2405 - cosine: 1.0000 - val_loss: 1088990.6492 - val_mse: 1088991.3750 - val_mae: 875.2811 - val_mape: 12922.1484 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109627.0062 - mse: 109626.9375 - mae: 209.2230 - mape: 32.8924 - cosine: 1.0000 - val_loss: 999685.5671 - val_mse: 999686.0625 - val_mae: 819.1177 - val_mape: 12040.6406 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109168.1685 - mse: 109168.2969 - mae: 208.9603 - mape: 32.9011 - cosine: 1.0000 - val_loss: 1054112.9608 - val_mse: 1054112.5000 - val_mae: 837.7842 - val_mape: 12302.8945 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 108738.7887 - mse: 108738.7344 - mae: 208.5184 - mape: 32.8405 - cosine: 1.0000 - val_loss: 955340.5940 - val_mse: 955339.6875 - val_mae: 806.1360 - val_mape: 11850.9229 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 108256.1844 - mse: 108256.3281 - mae: 208.1059 - mape: 32.8031 - cosine: 1.0000 - val_loss: 1004288.4589 - val_mse: 1004289.3750 - val_mae: 811.1788 - val_mape: 11914.4443 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 107983.4590 - mse: 107983.3359 - mae: 207.8393 - mape: 32.7933 - cosine: 1.0000 - val_loss: 1002035.5294 - val_mse: 1002036.3125 - val_mae: 830.4966 - val_mape: 12227.0488 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107676.6429 - mse: 107676.4375 - mae: 207.5518 - mape: 32.7471 - cosine: 1.0000 - val_loss: 941152.0703 - val_mse: 941152.0625 - val_mae: 808.7123 - val_mape: 11915.4785 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107252.1616 - mse: 107252.0703 - mae: 207.0950 - mape: 32.6750 - cosine: 1.0000 - val_loss: 1022679.3107 - val_mse: 1022679.0000 - val_mae: 846.5926 - val_mape: 12485.9688 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107120.5854 - mse: 107120.6484 - mae: 206.9514 - mape: 32.6545 - cosine: 1.0000 - val_loss: 999052.6305 - val_mse: 999052.8750 - val_mae: 833.9382 - val_mape: 12293.7285 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 106934.6073 - mse: 106934.4766 - mae: 206.7371 - mape: 32.6111 - cosine: 1.0000 - val_loss: 1009426.0308 - val_mse: 1009426.0625 - val_mae: 836.5474 - val_mape: 12329.9346 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 33%|███▎      | 12/36 [1:03:42<2:00:26, 301.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 151682.6891 - mse: 151682.6406 - mae: 248.1980 - mape: 39.9234 - cosine: 0.9947 - val_loss: 1004532.8949 - val_mse: 1004532.9375 - val_mae: 834.2473 - val_mape: 12301.5693 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 119167.3110 - mse: 119167.2891 - mae: 219.2755 - mape: 34.4071 - cosine: 1.0000 - val_loss: 971148.7249 - val_mse: 971149.3125 - val_mae: 826.4608 - val_mape: 12199.5156 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 116077.5201 - mse: 116077.5703 - mae: 215.9769 - mape: 33.9041 - cosine: 1.0000 - val_loss: 986456.9717 - val_mse: 986456.3125 - val_mae: 830.9849 - val_mape: 12256.8047 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 114120.8145 - mse: 114120.8047 - mae: 214.0141 - mape: 33.6039 - cosine: 1.0000 - val_loss: 1044302.2943 - val_mse: 1044301.5625 - val_mae: 851.5566 - val_mape: 12554.5098 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 112818.1351 - mse: 112818.1562 - mae: 212.6500 - mape: 33.4263 - cosine: 1.0000 - val_loss: 985301.2699 - val_mse: 985301.2500 - val_mae: 824.1067 - val_mape: 12146.5088 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 111809.7477 - mse: 111809.4844 - mae: 211.6585 - mape: 33.3231 - cosine: 1.0000 - val_loss: 1074291.5806 - val_mse: 1074291.3750 - val_mae: 865.0579 - val_mape: 12756.4863 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110902.4051 - mse: 110902.6406 - mae: 210.7000 - mape: 33.1892 - cosine: 1.0000 - val_loss: 1098520.8434 - val_mse: 1098521.7500 - val_mae: 873.6317 - val_mape: 12876.4189 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109993.5324 - mse: 109993.4688 - mae: 209.6451 - mape: 33.0456 - cosine: 1.0000 - val_loss: 1001121.2710 - val_mse: 1001121.8125 - val_mae: 827.1964 - val_mape: 12176.7119 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108994.1817 - mse: 108994.2344 - mae: 208.4899 - mape: 32.8330 - cosine: 1.0000 - val_loss: 1079582.3860 - val_mse: 1079583.3750 - val_mae: 860.4137 - val_mape: 12670.0625 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108405.3131 - mse: 108405.3359 - mae: 207.8615 - mape: 32.7922 - cosine: 1.0000 - val_loss: 989570.2508 - val_mse: 989570.5625 - val_mae: 807.9778 - val_mape: 11860.3818 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107939.0222 - mse: 107939.0391 - mae: 207.3191 - mape: 32.6958 - cosine: 1.0000 - val_loss: 970071.5086 - val_mse: 970072.4375 - val_mae: 804.5290 - val_mape: 11817.8291 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107568.3747 - mse: 107568.1797 - mae: 206.9431 - mape: 32.6230 - cosine: 1.0000 - val_loss: 997789.7808 - val_mse: 997788.8125 - val_mae: 823.5366 - val_mape: 12121.9600 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107233.2762 - mse: 107233.4297 - mae: 206.6057 - mape: 32.5900 - cosine: 1.0000 - val_loss: 1051950.7173 - val_mse: 1051950.1250 - val_mae: 849.9882 - val_mape: 12514.8818 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106791.5254 - mse: 106791.6484 - mae: 206.1180 - mape: 32.5349 - cosine: 1.0000 - val_loss: 1063882.6645 - val_mse: 1063880.7500 - val_mae: 842.6812 - val_mape: 12378.8730 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106549.1034 - mse: 106549.1016 - mae: 205.8336 - mape: 32.4870 - cosine: 1.0000 - val_loss: 978013.8234 - val_mse: 978014.2500 - val_mae: 809.0304 - val_mape: 11890.4004 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106143.9412 - mse: 106143.8984 - mae: 205.4815 - mape: 32.4754 - cosine: 1.0000 - val_loss: 1057310.6456 - val_mse: 1057311.5000 - val_mae: 845.2072 - val_mape: 12432.7832 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105876.6054 - mse: 105876.6875 - mae: 205.1533 - mape: 32.4328 - cosine: 1.0000 - val_loss: 1106458.4832 - val_mse: 1106458.0000 - val_mae: 857.4882 - val_mape: 12591.5645 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105575.9057 - mse: 105575.9375 - mae: 204.8789 - mape: 32.3685 - cosine: 1.0000 - val_loss: 1035530.7041 - val_mse: 1035530.6875 - val_mae: 851.1346 - val_mape: 12549.5586 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105379.6827 - mse: 105379.5781 - mae: 204.6933 - mape: 32.3414 - cosine: 1.0000 - val_loss: 982522.5598 - val_mse: 982523.0625 - val_mae: 828.6096 - val_mape: 12213.6221 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105200.7291 - mse: 105200.9453 - mae: 204.5213 - mape: 32.3084 - cosine: 1.0000 - val_loss: 1038333.7738 - val_mse: 1038334.2500 - val_mae: 828.1329 - val_mape: 12159.7031 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 36%|███▌      | 13/36 [1:08:25<1:53:20, 295.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 138731.3127 - mse: 138730.9844 - mae: 240.7182 - mape: 39.1885 - cosine: 1.0000 - val_loss: 819665.5748 - val_mse: 819665.5000 - val_mae: 738.5138 - val_mape: 10854.0273 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 119619.9352 - mse: 119619.7891 - mae: 220.2626 - mape: 34.8425 - cosine: 1.0000 - val_loss: 1017206.1798 - val_mse: 1017206.3125 - val_mae: 839.6499 - val_mape: 12386.1680 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 115923.7939 - mse: 115923.9453 - mae: 216.1098 - mape: 34.1806 - cosine: 1.0000 - val_loss: 970427.2268 - val_mse: 970426.3125 - val_mae: 827.7173 - val_mape: 12220.3535 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 113349.0037 - mse: 113348.9609 - mae: 213.2332 - mape: 33.6424 - cosine: 1.0000 - val_loss: 1071600.6873 - val_mse: 1071599.5000 - val_mae: 857.2102 - val_mape: 12628.3203 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 111552.0963 - mse: 111551.8438 - mae: 211.1809 - mape: 33.2936 - cosine: 1.0000 - val_loss: 981054.5612 - val_mse: 981054.5000 - val_mae: 817.0405 - val_mape: 12023.6904 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 110518.9584 - mse: 110519.1641 - mae: 209.9736 - mape: 33.0441 - cosine: 1.0000 - val_loss: 1097444.4446 - val_mse: 1097444.7500 - val_mae: 878.9343 - val_mape: 12964.2324 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 109671.6162 - mse: 109671.6250 - mae: 208.8958 - mape: 32.8488 - cosine: 1.0000 - val_loss: 1037722.7112 - val_mse: 1037722.6875 - val_mae: 843.4805 - val_mape: 12418.6748 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 108810.7446 - mse: 108810.8984 - mae: 207.9667 - mape: 32.7364 - cosine: 1.0000 - val_loss: 973656.5924 - val_mse: 973655.5000 - val_mae: 823.8259 - val_mape: 12139.2646 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 108220.8802 - mse: 108221.0312 - mae: 207.3328 - mape: 32.5863 - cosine: 1.0000 - val_loss: 938267.2364 - val_mse: 938267.8125 - val_mae: 804.5078 - val_mape: 11851.1270 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 107758.0008 - mse: 107758.1172 - mae: 206.8432 - mape: 32.5395 - cosine: 1.0000 - val_loss: 1005434.6264 - val_mse: 1005435.5000 - val_mae: 807.1348 - val_mape: 11828.2744 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 107276.1032 - mse: 107276.0703 - mae: 206.2722 - mape: 32.4359 - cosine: 1.0000 - val_loss: 1032291.0302 - val_mse: 1032291.4375 - val_mae: 840.1656 - val_mape: 12364.0029 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106991.3755 - mse: 106991.4531 - mae: 205.9472 - mape: 32.3833 - cosine: 1.0000 - val_loss: 1046554.5018 - val_mse: 1046553.8125 - val_mae: 835.0549 - val_mape: 12269.3359 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106582.7174 - mse: 106582.7188 - mae: 205.4464 - mape: 32.2849 - cosine: 1.0000 - val_loss: 1023146.6321 - val_mse: 1023146.6875 - val_mae: 842.4730 - val_mape: 12411.2510 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106388.9991 - mse: 106388.5625 - mae: 205.2350 - mape: 32.2397 - cosine: 1.0000 - val_loss: 1082960.2345 - val_mse: 1082960.7500 - val_mae: 854.5179 - val_mape: 12559.9307 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106021.8449 - mse: 106021.7578 - mae: 204.8203 - mape: 32.1874 - cosine: 1.0000 - val_loss: 969285.9771 - val_mse: 969286.1875 - val_mae: 813.6764 - val_mape: 11966.9785 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 105817.9855 - mse: 105817.9297 - mae: 204.5071 - mape: 32.1193 - cosine: 1.0000 - val_loss: 1070551.1071 - val_mse: 1070551.1250 - val_mae: 850.1116 - val_mape: 12498.4385 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 105606.6468 - mse: 105606.3906 - mae: 204.1924 - mape: 32.0587 - cosine: 1.0000 - val_loss: 1006679.4728 - val_mse: 1006679.5000 - val_mae: 824.8120 - val_mape: 12124.1426 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 105297.5574 - mse: 105297.2812 - mae: 203.9223 - mape: 31.9900 - cosine: 1.0000 - val_loss: 1064459.9467 - val_mse: 1064459.7500 - val_mae: 845.3774 - val_mape: 12420.9111 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 105181.6322 - mse: 105181.8281 - mae: 203.6693 - mape: 31.9384 - cosine: 1.0000 - val_loss: 1031868.7339 - val_mse: 1031868.2500 - val_mae: 840.0030 - val_mape: 12365.2676 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 104922.0566 - mse: 104921.7031 - mae: 203.4254 - mape: 31.8934 - cosine: 1.0000 - val_loss: 1035793.3521 - val_mse: 1035792.1875 - val_mae: 855.9716 - val_mape: 12638.7305 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 39%|███▉      | 14/36 [1:16:46<2:11:04, 357.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 144747.5461 - mse: 144747.7500 - mae: 246.5735 - mape: 40.8053 - cosine: 1.0000 - val_loss: 1065817.7541 - val_mse: 1065817.2500 - val_mae: 874.4015 - val_mape: 12942.4648 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 122524.6862 - mse: 122524.6172 - mae: 223.7560 - mape: 35.4552 - cosine: 1.0000 - val_loss: 1005085.2033 - val_mse: 1005084.6250 - val_mae: 826.9276 - val_mape: 12176.6475 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 118348.5467 - mse: 118348.6094 - mae: 218.3144 - mape: 34.4182 - cosine: 1.0000 - val_loss: 1018962.8232 - val_mse: 1018962.3750 - val_mae: 826.8286 - val_mape: 12155.3340 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 115764.0291 - mse: 115763.9609 - mae: 215.2215 - mape: 33.8911 - cosine: 1.0000 - val_loss: 1023177.3023 - val_mse: 1023177.3750 - val_mae: 841.7895 - val_mape: 12406.0400 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113841.5153 - mse: 113841.3047 - mae: 213.1115 - mape: 33.5605 - cosine: 1.0000 - val_loss: 1073918.1085 - val_mse: 1073918.1250 - val_mae: 871.7005 - val_mape: 12867.0449 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 112313.9914 - mse: 112314.0625 - mae: 211.4768 - mape: 33.2795 - cosine: 1.0000 - val_loss: 1029423.7204 - val_mse: 1029423.5000 - val_mae: 839.1766 - val_mape: 12354.3896 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111197.9240 - mse: 111197.8203 - mae: 210.3181 - mape: 33.1064 - cosine: 1.0000 - val_loss: 1035954.8906 - val_mse: 1035954.3750 - val_mae: 846.4633 - val_mape: 12471.1152 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110211.9262 - mse: 110211.5625 - mae: 209.2746 - mape: 32.9253 - cosine: 1.0000 - val_loss: 1095065.6002 - val_mse: 1095066.1250 - val_mae: 855.8015 - val_mape: 12581.6611 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109335.5373 - mse: 109335.5469 - mae: 208.1269 - mape: 32.6564 - cosine: 1.0000 - val_loss: 1006491.2418 - val_mse: 1006490.0625 - val_mae: 828.5046 - val_mape: 12188.8896 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108749.0903 - mse: 108749.1250 - mae: 207.4864 - mape: 32.5431 - cosine: 1.0000 - val_loss: 1018413.0757 - val_mse: 1018412.9375 - val_mae: 833.4791 - val_mape: 12258.7295 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108135.7581 - mse: 108135.7031 - mae: 206.8311 - mape: 32.4031 - cosine: 1.0000 - val_loss: 1054944.2471 - val_mse: 1054943.5000 - val_mae: 867.0090 - val_mape: 12806.1738 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107685.7678 - mse: 107685.8281 - mae: 206.3063 - mape: 32.2972 - cosine: 1.0000 - val_loss: 1038710.4912 - val_mse: 1038710.2500 - val_mae: 834.1396 - val_mape: 12253.8486 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107183.5592 - mse: 107183.5938 - mae: 205.7668 - mape: 32.1946 - cosine: 1.0000 - val_loss: 1036733.3779 - val_mse: 1036732.6875 - val_mae: 843.5919 - val_mape: 12422.4971 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106664.8495 - mse: 106665.0078 - mae: 205.2850 - mape: 32.1383 - cosine: 1.0000 - val_loss: 1115289.7975 - val_mse: 1115289.8750 - val_mae: 864.9604 - val_mape: 12710.6025 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106273.7703 - mse: 106273.9297 - mae: 204.7909 - mape: 32.0296 - cosine: 1.0000 - val_loss: 1063036.1247 - val_mse: 1063036.1250 - val_mae: 845.9658 - val_mape: 12428.5938 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105860.2107 - mse: 105860.2031 - mae: 204.3907 - mape: 31.9370 - cosine: 1.0000 - val_loss: 930310.9349 - val_mse: 930310.8125 - val_mae: 785.8010 - val_mape: 11535.5146 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105446.4159 - mse: 105446.4531 - mae: 203.9308 - mape: 31.8946 - cosine: 1.0000 - val_loss: 1040528.2504 - val_mse: 1040527.9375 - val_mae: 853.9344 - val_mape: 12588.0264 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105163.9308 - mse: 105164.0625 - mae: 203.6614 - mape: 31.8730 - cosine: 1.0000 - val_loss: 1011471.9763 - val_mse: 1011472.6250 - val_mae: 835.0921 - val_mape: 12295.0195 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104866.3340 - mse: 104866.3516 - mae: 203.3111 - mape: 31.8251 - cosine: 1.0000 - val_loss: 1115690.6154 - val_mse: 1115690.5000 - val_mae: 869.2168 - val_mape: 12774.1865 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104665.1324 - mse: 104665.3750 - mae: 203.0523 - mape: 31.7453 - cosine: 1.0000 - val_loss: 1015201.9426 - val_mse: 1015201.8125 - val_mae: 829.8757 - val_mape: 12200.7334 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 42%|████▏     | 15/36 [1:21:26<1:56:55, 334.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 24s 21us/step - loss: 131923.3480 - mse: 131923.4531 - mae: 232.4297 - mape: 37.1388 - cosine: 1.0000 - val_loss: 1032114.2834 - val_mse: 1032114.3750 - val_mae: 840.2362 - val_mape: 12371.4678 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 118899.6851 - mse: 118899.6484 - mae: 218.9149 - mape: 34.5992 - cosine: 1.0000 - val_loss: 1065076.9011 - val_mse: 1065077.1250 - val_mae: 861.7991 - val_mape: 12711.5498 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 24s 21us/step - loss: 115533.9045 - mse: 115533.9062 - mae: 215.5743 - mape: 34.2254 - cosine: 1.0000 - val_loss: 945289.2358 - val_mse: 945290.3750 - val_mae: 793.8139 - val_mape: 11667.5186 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 112583.6036 - mse: 112583.7422 - mae: 212.6119 - mape: 33.7556 - cosine: 1.0000 - val_loss: 977546.6821 - val_mse: 977545.1250 - val_mae: 830.1305 - val_mape: 12255.8281 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 111039.1813 - mse: 111039.5078 - mae: 210.8441 - mape: 33.4560 - cosine: 1.0000 - val_loss: 1055611.9729 - val_mse: 1055611.5000 - val_mae: 852.7769 - val_mape: 12565.3164 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 110072.1707 - mse: 110072.3516 - mae: 209.6577 - mape: 33.1817 - cosine: 1.0000 - val_loss: 1031206.3868 - val_mse: 1031206.3125 - val_mae: 835.7904 - val_mape: 12297.4219 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 109382.0501 - mse: 109382.2734 - mae: 208.7946 - mape: 33.0058 - cosine: 1.0000 - val_loss: 937751.6211 - val_mse: 937751.5000 - val_mae: 800.6875 - val_mape: 11786.5244 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 108835.0568 - mse: 108835.2031 - mae: 208.2145 - mape: 32.9118 - cosine: 1.0000 - val_loss: 925815.9196 - val_mse: 925816.3125 - val_mae: 795.2120 - val_mape: 11698.8926 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 108304.3290 - mse: 108304.0156 - mae: 207.5870 - mape: 32.7640 - cosine: 1.0000 - val_loss: 977600.2180 - val_mse: 977601.3750 - val_mae: 810.8711 - val_mape: 11919.5303 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 107921.5212 - mse: 107921.3438 - mae: 207.1419 - mape: 32.6820 - cosine: 1.0000 - val_loss: 1046007.0551 - val_mse: 1046006.1875 - val_mae: 843.0257 - val_mape: 12405.9355 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 107363.9301 - mse: 107363.9609 - mae: 206.4440 - mape: 32.5712 - cosine: 1.0000 - val_loss: 981003.2144 - val_mse: 981003.4375 - val_mae: 813.4630 - val_mape: 11960.2832 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106940.0261 - mse: 106939.8672 - mae: 205.7939 - mape: 32.4377 - cosine: 1.0000 - val_loss: 1071840.8136 - val_mse: 1071840.7500 - val_mae: 854.2806 - val_mape: 12564.6973 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106400.8415 - mse: 106400.8516 - mae: 205.1673 - mape: 32.2847 - cosine: 1.0000 - val_loss: 1010238.0846 - val_mse: 1010238.7500 - val_mae: 827.0753 - val_mape: 12159.6025 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 106074.2204 - mse: 106074.2109 - mae: 204.7416 - mape: 32.1993 - cosine: 1.0000 - val_loss: 1058673.8444 - val_mse: 1058673.2500 - val_mae: 857.6058 - val_mape: 12637.0176 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 105721.4497 - mse: 105721.4531 - mae: 204.3685 - mape: 32.1271 - cosine: 1.0000 - val_loss: 997920.5849 - val_mse: 997920.8125 - val_mae: 823.2149 - val_mape: 12104.4160 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 105503.0500 - mse: 105503.0703 - mae: 204.0847 - mape: 32.0699 - cosine: 1.0000 - val_loss: 936639.2349 - val_mse: 936640.3750 - val_mae: 794.5078 - val_mape: 11670.1475 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 105244.0643 - mse: 105244.1797 - mae: 203.6446 - mape: 31.9848 - cosine: 1.0000 - val_loss: 1030417.3323 - val_mse: 1030418.2500 - val_mae: 842.5005 - val_mape: 12404.4287 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 104934.2226 - mse: 104934.5156 - mae: 203.3105 - mape: 31.9241 - cosine: 1.0000 - val_loss: 996548.7984 - val_mse: 996547.9375 - val_mae: 840.9012 - val_mape: 12410.3945 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 104674.4375 - mse: 104674.3125 - mae: 202.8878 - mape: 31.8583 - cosine: 1.0000 - val_loss: 988802.9159 - val_mse: 988803.1875 - val_mae: 830.0223 - val_mape: 12236.6963 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 104457.9105 - mse: 104458.2188 - mae: 202.6237 - mape: 31.7587 - cosine: 1.0000 - val_loss: 1071355.9415 - val_mse: 1071356.6250 - val_mae: 867.8842 - val_mape: 12802.1982 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 44%|████▍     | 16/36 [1:29:51<2:08:29, 385.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 152701.0512 - mse: 152701.0938 - mae: 253.1800 - mape: 42.0554 - cosine: 1.0000 - val_loss: 942174.2215 - val_mse: 942174.2500 - val_mae: 817.5081 - val_mape: 12106.8721 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 126994.9841 - mse: 126995.0000 - mae: 229.3110 - mape: 37.0553 - cosine: 1.0000 - val_loss: 920732.1320 - val_mse: 920731.9375 - val_mae: 788.8206 - val_mape: 11609.6729 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 118939.7275 - mse: 118939.8203 - mae: 219.8065 - mape: 34.8875 - cosine: 1.0000 - val_loss: 1177020.7934 - val_mse: 1177022.2500 - val_mae: 907.1316 - val_mape: 13384.2363 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 116577.2820 - mse: 116577.0703 - mae: 217.3206 - mape: 34.4734 - cosine: 1.0000 - val_loss: 1029607.5517 - val_mse: 1029607.4375 - val_mae: 824.0610 - val_mape: 12099.3643 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 115333.6795 - mse: 115333.8750 - mae: 215.9185 - mape: 34.2069 - cosine: 1.0000 - val_loss: 1042604.2640 - val_mse: 1042604.5000 - val_mae: 847.6900 - val_mape: 12494.7354 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 113916.7638 - mse: 113916.8359 - mae: 214.3133 - mape: 33.9601 - cosine: 1.0000 - val_loss: 1020523.1252 - val_mse: 1020523.1250 - val_mae: 837.2079 - val_mape: 12337.3877 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 112813.4858 - mse: 112813.5000 - mae: 213.2438 - mape: 33.8406 - cosine: 1.0000 - val_loss: 1057181.5499 - val_mse: 1057180.8750 - val_mae: 855.4843 - val_mape: 12611.9277 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 112013.0718 - mse: 112013.0234 - mae: 212.4709 - mape: 33.7255 - cosine: 1.0000 - val_loss: 1087478.8449 - val_mse: 1087478.8750 - val_mae: 868.3583 - val_mape: 12803.1123 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 111208.8659 - mse: 111208.8047 - mae: 211.5817 - mape: 33.6043 - cosine: 1.0000 - val_loss: 984448.9428 - val_mse: 984448.9375 - val_mae: 808.9771 - val_mape: 11882.8486 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110634.2171 - mse: 110634.2031 - mae: 210.9583 - mape: 33.5120 - cosine: 1.0000 - val_loss: 898181.7856 - val_mse: 898181.5000 - val_mae: 787.7726 - val_mape: 11603.3926 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110121.5023 - mse: 110121.5078 - mae: 210.4555 - mape: 33.4136 - cosine: 1.0000 - val_loss: 1131183.7593 - val_mse: 1131184.6250 - val_mae: 890.7361 - val_mape: 13142.3750 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109678.6735 - mse: 109678.5625 - mae: 209.8891 - mape: 33.2917 - cosine: 1.0000 - val_loss: 1022579.4171 - val_mse: 1022579.6250 - val_mae: 842.1984 - val_mape: 12418.6533 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109337.5706 - mse: 109337.3984 - mae: 209.4621 - mape: 33.1787 - cosine: 1.0000 - val_loss: 974392.5247 - val_mse: 974391.8750 - val_mae: 826.3373 - val_mape: 12186.4600 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109023.1312 - mse: 109023.2500 - mae: 209.0096 - mape: 33.0498 - cosine: 1.0000 - val_loss: 1005245.7348 - val_mse: 1005245.1875 - val_mae: 821.9228 - val_mape: 12077.1172 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 108488.2398 - mse: 108488.2656 - mae: 208.3305 - mape: 32.8561 - cosine: 1.0000 - val_loss: 940662.2712 - val_mse: 940662.3125 - val_mae: 787.9632 - val_mape: 11561.4619 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107964.8858 - mse: 107964.9844 - mae: 207.5443 - mape: 32.7105 - cosine: 1.0000 - val_loss: 1002342.7673 - val_mse: 1002341.8125 - val_mae: 834.3099 - val_mape: 12296.6406 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107496.9554 - mse: 107497.0781 - mae: 207.0247 - mape: 32.6420 - cosine: 1.0000 - val_loss: 980225.1265 - val_mse: 980225.3750 - val_mae: 819.9786 - val_mape: 12070.5781 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107174.4328 - mse: 107174.5078 - mae: 206.7211 - mape: 32.5829 - cosine: 1.0000 - val_loss: 1071905.3706 - val_mse: 1071905.1250 - val_mae: 853.1190 - val_mape: 12544.3506 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 106864.2575 - mse: 106864.2812 - mae: 206.3460 - mape: 32.5192 - cosine: 1.0000 - val_loss: 1049322.1075 - val_mse: 1049322.6250 - val_mae: 854.6038 - val_mape: 12598.4980 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 106434.7648 - mse: 106434.8203 - mae: 205.8795 - mape: 32.4407 - cosine: 1.0000 - val_loss: 1044538.2075 - val_mse: 1044538.7500 - val_mae: 842.8510 - val_mape: 12396.5918 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 47%|████▋     | 17/36 [1:32:40<1:41:27, 320.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 159578.0168 - mse: 159578.0000 - mae: 257.8893 - mape: 42.6263 - cosine: 0.9999 - val_loss: 1010465.0505 - val_mse: 1010465.1250 - val_mae: 839.8171 - val_mape: 12404.6416 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 125895.9906 - mse: 125896.0938 - mae: 227.6119 - mape: 36.6317 - cosine: 1.0000 - val_loss: 1021223.5864 - val_mse: 1021223.8125 - val_mae: 851.6021 - val_mape: 12587.3047 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 120489.4067 - mse: 120489.3125 - mae: 221.0452 - mape: 35.1492 - cosine: 1.0000 - val_loss: 1050169.1634 - val_mse: 1050169.0000 - val_mae: 858.8041 - val_mape: 12676.4932 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 118696.8339 - mse: 118696.8203 - mae: 218.6373 - mape: 34.5246 - cosine: 1.0000 - val_loss: 1018099.2314 - val_mse: 1018099.5000 - val_mae: 839.3923 - val_mape: 12373.9131 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 117304.6898 - mse: 117304.6172 - mae: 216.8760 - mape: 34.1402 - cosine: 1.0000 - val_loss: 1030595.6219 - val_mse: 1030595.1250 - val_mae: 834.2034 - val_mape: 12270.9814 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 116372.2033 - mse: 116372.0156 - mae: 215.8142 - mape: 33.8749 - cosine: 1.0000 - val_loss: 1105487.2308 - val_mse: 1105487.8750 - val_mae: 867.2442 - val_mape: 12765.7510 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 115354.9173 - mse: 115354.9922 - mae: 214.7312 - mape: 33.6433 - cosine: 1.0000 - val_loss: 1037272.5385 - val_mse: 1037273.3125 - val_mae: 839.9294 - val_mape: 12360.5039 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 114335.2377 - mse: 114335.1641 - mae: 213.5959 - mape: 33.4289 - cosine: 1.0000 - val_loss: 1009685.9289 - val_mse: 1009685.9375 - val_mae: 844.6411 - val_mape: 12468.3066 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 113615.1549 - mse: 113615.0859 - mae: 212.9321 - mape: 33.3419 - cosine: 1.0000 - val_loss: 1026601.1578 - val_mse: 1026602.0625 - val_mae: 836.9136 - val_mape: 12321.8672 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 112766.2613 - mse: 112766.3750 - mae: 212.1552 - mape: 33.2623 - cosine: 1.0000 - val_loss: 1019933.7255 - val_mse: 1019933.6875 - val_mae: 837.5444 - val_mape: 12339.1162 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 112178.2009 - mse: 112178.1953 - mae: 211.6525 - mape: 33.1905 - cosine: 1.0000 - val_loss: 1125458.1950 - val_mse: 1125457.3750 - val_mae: 877.5594 - val_mape: 12921.9473 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 111650.5398 - mse: 111650.4453 - mae: 211.1294 - mape: 33.0879 - cosine: 1.0000 - val_loss: 1010957.2794 - val_mse: 1010957.0000 - val_mae: 828.7969 - val_mape: 12193.0098 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110958.2733 - mse: 110958.3125 - mae: 210.4104 - mape: 32.9807 - cosine: 1.0000 - val_loss: 963188.6168 - val_mse: 963188.9375 - val_mae: 814.0339 - val_mape: 11983.6934 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110276.7230 - mse: 110276.6719 - mae: 209.5568 - mape: 32.7748 - cosine: 1.0000 - val_loss: 1065181.8660 - val_mse: 1065181.8750 - val_mae: 857.0441 - val_mape: 12627.8164 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 109388.4595 - mse: 109388.2266 - mae: 208.6555 - mape: 32.6682 - cosine: 1.0000 - val_loss: 1030713.6315 - val_mse: 1030713.6250 - val_mae: 856.2525 - val_mape: 12644.1875 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 108919.2598 - mse: 108919.1094 - mae: 208.1346 - mape: 32.6137 - cosine: 1.0000 - val_loss: 1111875.2191 - val_mse: 1111875.5000 - val_mae: 867.0241 - val_mape: 12760.4854 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 108424.4310 - mse: 108424.4531 - mae: 207.7156 - mape: 32.5605 - cosine: 1.0000 - val_loss: 1065946.6708 - val_mse: 1065946.5000 - val_mae: 868.8855 - val_mape: 12825.0850 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 107994.1679 - mse: 107994.2891 - mae: 207.2992 - mape: 32.4967 - cosine: 1.0000 - val_loss: 929144.9951 - val_mse: 929144.6250 - val_mae: 788.7307 - val_mape: 11585.2939 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107653.7541 - mse: 107653.7734 - mae: 206.8865 - mape: 32.4300 - cosine: 1.0000 - val_loss: 1018273.9333 - val_mse: 1018274.1875 - val_mae: 835.5991 - val_mape: 12294.5146 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107391.3991 - mse: 107391.5781 - mae: 206.6921 - mape: 32.4169 - cosine: 1.0000 - val_loss: 1022331.8155 - val_mse: 1022331.3125 - val_mae: 847.5392 - val_mape: 12500.5225 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 50%|█████     | 18/36 [1:35:30<1:22:34, 275.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 141043.9422 - mse: 141043.9375 - mae: 241.0112 - mape: 38.9543 - cosine: 0.9999 - val_loss: 1110820.9986 - val_mse: 1110820.0000 - val_mae: 884.3462 - val_mape: 13066.9609 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 120613.3169 - mse: 120613.1797 - mae: 221.2493 - mape: 35.0791 - cosine: 1.0000 - val_loss: 929829.9891 - val_mse: 929829.6250 - val_mae: 788.8857 - val_mape: 11603.1455 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 118334.0842 - mse: 118333.8594 - mae: 218.1427 - mape: 34.3487 - cosine: 1.0000 - val_loss: 1099375.6177 - val_mse: 1099376.2500 - val_mae: 876.2868 - val_mape: 12932.2207 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 116252.7134 - mse: 116252.6562 - mae: 215.2919 - mape: 33.6624 - cosine: 1.0000 - val_loss: 1031252.3499 - val_mse: 1031252.7500 - val_mae: 859.9827 - val_mape: 12720.6807 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 114620.8195 - mse: 114620.9141 - mae: 213.2392 - mape: 33.2475 - cosine: 1.0000 - val_loss: 924212.6894 - val_mse: 924213.0625 - val_mae: 784.2628 - val_mape: 11513.9736 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113634.4977 - mse: 113634.4375 - mae: 212.1684 - mape: 33.0566 - cosine: 1.0000 - val_loss: 1034152.1532 - val_mse: 1034154.2500 - val_mae: 829.1143 - val_mape: 12169.2061 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 112569.2306 - mse: 112569.4141 - mae: 210.9567 - mape: 32.8240 - cosine: 1.0000 - val_loss: 1068398.2032 - val_mse: 1068399.0000 - val_mae: 862.6375 - val_mape: 12717.4062 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111379.0421 - mse: 111379.0781 - mae: 209.7258 - mape: 32.6427 - cosine: 1.0000 - val_loss: 1101907.7987 - val_mse: 1101906.6250 - val_mae: 872.4020 - val_mape: 12846.5977 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110126.6073 - mse: 110126.5391 - mae: 208.5584 - mape: 32.4814 - cosine: 1.0000 - val_loss: 1088646.7757 - val_mse: 1088645.8750 - val_mae: 854.2410 - val_mape: 12564.2383 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108890.3669 - mse: 108890.4688 - mae: 207.3854 - mape: 32.3422 - cosine: 1.0000 - val_loss: 1056762.9286 - val_mse: 1056762.6250 - val_mae: 868.3211 - val_mape: 12824.9111 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107853.3856 - mse: 107853.2891 - mae: 206.6131 - mape: 32.3005 - cosine: 1.0000 - val_loss: 1038562.8227 - val_mse: 1038562.7500 - val_mae: 854.5733 - val_mape: 12603.7480 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107055.4611 - mse: 107055.4453 - mae: 205.8406 - mape: 32.1677 - cosine: 1.0000 - val_loss: 1053628.0077 - val_mse: 1053627.1250 - val_mae: 855.4886 - val_mape: 12606.7998 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106601.6070 - mse: 106601.6641 - mae: 205.3743 - mape: 32.1453 - cosine: 1.0000 - val_loss: 1022083.2104 - val_mse: 1022082.8750 - val_mae: 823.3343 - val_mape: 12086.1904 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106132.6786 - mse: 106132.8203 - mae: 204.9098 - mape: 32.0699 - cosine: 1.0000 - val_loss: 1087168.1027 - val_mse: 1087168.6250 - val_mae: 875.8076 - val_mape: 12934.1680 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 105735.9665 - mse: 105736.0781 - mae: 204.5619 - mape: 32.0477 - cosine: 1.0000 - val_loss: 1065437.9747 - val_mse: 1065438.2500 - val_mae: 835.5406 - val_mape: 12256.1289 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105460.4684 - mse: 105460.4297 - mae: 204.2565 - mape: 31.9938 - cosine: 1.0000 - val_loss: 919327.3002 - val_mse: 919327.8750 - val_mae: 794.8351 - val_mape: 11691.5664 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105087.5302 - mse: 105087.5625 - mae: 203.8318 - mape: 31.9276 - cosine: 1.0000 - val_loss: 1031639.2767 - val_mse: 1031639.0625 - val_mae: 839.4221 - val_mape: 12346.8838 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104908.1888 - mse: 104908.1641 - mae: 203.6621 - mape: 31.9090 - cosine: 1.0000 - val_loss: 1022048.3159 - val_mse: 1022048.4375 - val_mae: 832.5453 - val_mape: 12232.9990 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 104729.4312 - mse: 104729.2891 - mae: 203.4094 - mape: 31.8404 - cosine: 1.0000 - val_loss: 1021938.6399 - val_mse: 1021938.5625 - val_mae: 842.0016 - val_mape: 12401.2920 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104542.7203 - mse: 104542.8984 - mae: 203.1825 - mape: 31.8197 - cosine: 1.0000 - val_loss: 1094315.1323 - val_mse: 1094314.3750 - val_mae: 864.3062 - val_mape: 12718.1221 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 53%|█████▎    | 19/36 [1:40:11<1:18:31, 277.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 139953.0645 - mse: 139953.1250 - mae: 240.0620 - mape: 38.5966 - cosine: 0.9999 - val_loss: 1041144.4756 - val_mse: 1041144.8750 - val_mae: 854.8661 - val_mape: 12624.4668 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 120029.3784 - mse: 120029.3828 - mae: 220.1625 - mape: 34.7454 - cosine: 1.0000 - val_loss: 999458.8301 - val_mse: 999459.0000 - val_mae: 828.1246 - val_mape: 12201.1035 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 116925.4794 - mse: 116925.6406 - mae: 216.8617 - mape: 34.2990 - cosine: 1.0000 - val_loss: 1019476.6742 - val_mse: 1019475.9375 - val_mae: 829.3767 - val_mape: 12201.7188 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113969.7333 - mse: 113969.8828 - mae: 214.0425 - mape: 34.0177 - cosine: 1.0000 - val_loss: 1037538.9802 - val_mse: 1037540.3125 - val_mae: 848.9034 - val_mape: 12517.1787 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 112185.5606 - mse: 112185.7422 - mae: 212.3128 - mape: 33.7601 - cosine: 1.0000 - val_loss: 974299.5064 - val_mse: 974300.0000 - val_mae: 809.7739 - val_mape: 11902.6523 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111362.7298 - mse: 111362.5234 - mae: 211.5654 - mape: 33.6271 - cosine: 1.0000 - val_loss: 989997.4548 - val_mse: 989997.8125 - val_mae: 820.7355 - val_mape: 12074.8311 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110526.7942 - mse: 110526.7812 - mae: 210.4841 - mape: 33.3319 - cosine: 1.0000 - val_loss: 1066182.4161 - val_mse: 1066182.3750 - val_mae: 855.9952 - val_mape: 12608.9873 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 109718.8328 - mse: 109718.7734 - mae: 209.5580 - mape: 33.1026 - cosine: 1.0000 - val_loss: 993270.4353 - val_mse: 993270.6875 - val_mae: 811.9973 - val_mape: 11925.6826 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109110.7579 - mse: 109110.7891 - mae: 208.7292 - mape: 32.9536 - cosine: 1.0000 - val_loss: 983340.6957 - val_mse: 983340.7500 - val_mae: 813.9880 - val_mape: 11961.0371 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108469.7462 - mse: 108469.7031 - mae: 207.9486 - mape: 32.8423 - cosine: 1.0000 - val_loss: 988239.3169 - val_mse: 988238.4375 - val_mae: 815.2344 - val_mape: 11984.4971 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107738.8149 - mse: 107738.7656 - mae: 207.0183 - mape: 32.6728 - cosine: 1.0000 - val_loss: 1074157.7255 - val_mse: 1074157.5000 - val_mae: 845.1567 - val_mape: 12408.0400 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 107246.7739 - mse: 107246.7812 - mae: 206.4560 - mape: 32.5757 - cosine: 1.0000 - val_loss: 962052.7848 - val_mse: 962052.1250 - val_mae: 801.7768 - val_mape: 11777.8359 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106820.8145 - mse: 106820.8438 - mae: 205.9893 - mape: 32.4887 - cosine: 1.0000 - val_loss: 996656.2999 - val_mse: 996656.5000 - val_mae: 815.5566 - val_mape: 11980.4902 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106530.2648 - mse: 106530.1172 - mae: 205.6037 - mape: 32.4302 - cosine: 1.0000 - val_loss: 1077817.6282 - val_mse: 1077819.1250 - val_mae: 856.9693 - val_mape: 12610.1816 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106072.3194 - mse: 106072.1953 - mae: 205.0205 - mape: 32.3277 - cosine: 1.0000 - val_loss: 994632.0740 - val_mse: 994631.2500 - val_mae: 827.4027 - val_mape: 12191.0537 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105880.0174 - mse: 105879.9375 - mae: 204.7648 - mape: 32.2387 - cosine: 1.0000 - val_loss: 1057419.0706 - val_mse: 1057420.2500 - val_mae: 839.1390 - val_mape: 12326.7188 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105583.4133 - mse: 105583.3281 - mae: 204.4904 - mape: 32.1932 - cosine: 1.0000 - val_loss: 943410.8359 - val_mse: 943410.0000 - val_mae: 797.4003 - val_mape: 11719.0361 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105326.0624 - mse: 105326.2734 - mae: 204.0603 - mape: 32.1173 - cosine: 1.0000 - val_loss: 1018340.0086 - val_mse: 1018338.6250 - val_mae: 837.1301 - val_mape: 12331.1338 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105016.3441 - mse: 105016.2578 - mae: 203.7621 - mape: 32.0879 - cosine: 1.0000 - val_loss: 974651.2194 - val_mse: 974650.5000 - val_mae: 812.0471 - val_mape: 11932.6895 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 104708.4182 - mse: 104708.5469 - mae: 203.2864 - mape: 32.0257 - cosine: 1.0000 - val_loss: 1012051.5648 - val_mse: 1012050.9375 - val_mae: 833.8851 - val_mape: 12266.7256 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 56%|█████▌    | 20/36 [1:44:57<1:14:37, 279.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 156074.1608 - mse: 156074.2031 - mae: 252.6472 - mape: 41.0759 - cosine: 0.9998 - val_loss: 1014924.2235 - val_mse: 1014924.2500 - val_mae: 832.1876 - val_mape: 12255.8535 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 120324.0533 - mse: 120324.1250 - mae: 220.2907 - mape: 34.6281 - cosine: 1.0000 - val_loss: 1052553.6891 - val_mse: 1052553.3750 - val_mae: 848.8597 - val_mape: 12501.0303 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 117788.0980 - mse: 117788.1875 - mae: 217.3250 - mape: 34.0548 - cosine: 1.0000 - val_loss: 973506.5073 - val_mse: 973506.5000 - val_mae: 825.9733 - val_mape: 12195.6797 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 116694.1506 - mse: 116694.3594 - mae: 216.1154 - mape: 33.8299 - cosine: 1.0000 - val_loss: 919579.6385 - val_mse: 919579.0625 - val_mae: 779.3233 - val_mape: 11446.8574 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 115833.4049 - mse: 115833.1953 - mae: 215.2255 - mape: 33.7180 - cosine: 1.0000 - val_loss: 1033407.4181 - val_mse: 1033407.1250 - val_mae: 854.3738 - val_mape: 12613.4844 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 114834.8697 - mse: 114834.6250 - mae: 214.1438 - mape: 33.5640 - cosine: 1.0000 - val_loss: 1020761.6986 - val_mse: 1020761.2500 - val_mae: 840.5729 - val_mape: 12382.1689 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 114017.3202 - mse: 114017.2500 - mae: 213.2254 - mape: 33.4103 - cosine: 1.0000 - val_loss: 1019572.0543 - val_mse: 1019572.1250 - val_mae: 844.8294 - val_mape: 12461.6152 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 113339.2662 - mse: 113339.1562 - mae: 212.4548 - mape: 33.2611 - cosine: 1.0000 - val_loss: 925097.1426 - val_mse: 925097.4375 - val_mae: 782.7111 - val_mape: 11492.5508 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 112741.2393 - mse: 112741.2969 - mae: 211.7533 - mape: 33.1518 - cosine: 1.0000 - val_loss: 1018015.0269 - val_mse: 1018015.6250 - val_mae: 851.7065 - val_mape: 12575.2412 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 112301.3317 - mse: 112301.3750 - mae: 211.3478 - mape: 33.1298 - cosine: 1.0000 - val_loss: 998395.0732 - val_mse: 998395.3750 - val_mae: 831.6857 - val_mape: 12259.3125 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 111953.4246 - mse: 111953.2812 - mae: 210.9220 - mape: 33.0381 - cosine: 1.0000 - val_loss: 987603.5965 - val_mse: 987604.3750 - val_mae: 831.5406 - val_mape: 12264.0547 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 111530.6673 - mse: 111530.7188 - mae: 210.4485 - mape: 32.9988 - cosine: 1.0000 - val_loss: 1051636.8369 - val_mse: 1051636.2500 - val_mae: 862.0494 - val_mape: 12729.8887 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 111190.9275 - mse: 111190.8359 - mae: 210.1828 - mape: 32.9391 - cosine: 1.0000 - val_loss: 1099675.6196 - val_mse: 1099676.0000 - val_mae: 877.1779 - val_mape: 12936.2168 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 110872.3045 - mse: 110872.3906 - mae: 209.8295 - mape: 32.9072 - cosine: 1.0000 - val_loss: 1030025.8859 - val_mse: 1030025.6250 - val_mae: 833.4200 - val_mape: 12249.8662 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110679.5441 - mse: 110679.6016 - mae: 209.6082 - mape: 32.8757 - cosine: 1.0000 - val_loss: 978355.6606 - val_mse: 978355.5625 - val_mae: 819.1756 - val_mape: 12063.8037 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110267.4343 - mse: 110267.4453 - mae: 209.1933 - mape: 32.7976 - cosine: 1.0000 - val_loss: 959496.8560 - val_mse: 959496.1250 - val_mae: 812.3920 - val_mape: 11968.5830 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110000.7363 - mse: 110000.8359 - mae: 208.9970 - mape: 32.8034 - cosine: 1.0000 - val_loss: 1032139.8674 - val_mse: 1032140.1250 - val_mae: 840.9691 - val_mape: 12381.0410 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109639.6389 - mse: 109639.6328 - mae: 208.7365 - mape: 32.7904 - cosine: 1.0000 - val_loss: 1060346.1506 - val_mse: 1060346.0000 - val_mae: 849.3445 - val_mape: 12501.1680 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109341.3085 - mse: 109341.2422 - mae: 208.4077 - mape: 32.7327 - cosine: 1.0000 - val_loss: 1042057.4650 - val_mse: 1042057.3125 - val_mae: 842.6975 - val_mape: 12401.9102 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 108978.1934 - mse: 108978.2031 - mae: 208.0439 - mape: 32.6962 - cosine: 1.0000 - val_loss: 1045347.6021 - val_mse: 1045347.8750 - val_mae: 838.5821 - val_mape: 12330.0176 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 58%|█████▊    | 21/36 [1:47:47<1:01:39, 246.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 140856.2083 - mse: 140856.1562 - mae: 241.4800 - mape: 38.9676 - cosine: 1.0000 - val_loss: 952161.4376 - val_mse: 952161.0625 - val_mae: 811.1222 - val_mape: 11958.0615 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 121307.8435 - mse: 121307.8203 - mae: 221.6383 - mape: 34.7948 - cosine: 1.0000 - val_loss: 1013496.4541 - val_mse: 1013495.8125 - val_mae: 839.9173 - val_mape: 12394.7314 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 117299.9547 - mse: 117299.9297 - mae: 217.4253 - mape: 34.2868 - cosine: 1.0000 - val_loss: 1080971.7555 - val_mse: 1080972.5000 - val_mae: 875.3614 - val_mape: 12937.1602 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 114836.2721 - mse: 114835.9844 - mae: 215.0995 - mape: 34.0383 - cosine: 1.0000 - val_loss: 982838.9323 - val_mse: 982838.1250 - val_mae: 836.0762 - val_mape: 12350.8906 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 112904.8227 - mse: 112904.7109 - mae: 213.0779 - mape: 33.7539 - cosine: 1.0000 - val_loss: 1117141.1003 - val_mse: 1117140.2500 - val_mae: 856.4854 - val_mape: 12573.4160 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111589.4006 - mse: 111589.3516 - mae: 211.6906 - mape: 33.5138 - cosine: 1.0000 - val_loss: 978309.2882 - val_mse: 978309.3125 - val_mae: 824.0309 - val_mape: 12143.6826 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 110448.3986 - mse: 110448.2109 - mae: 210.1555 - mape: 33.2004 - cosine: 1.0000 - val_loss: 1110968.7247 - val_mse: 1110967.0000 - val_mae: 883.9611 - val_mape: 13039.4189 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109787.3595 - mse: 109787.2812 - mae: 209.3447 - mape: 32.9858 - cosine: 1.0000 - val_loss: 944099.3983 - val_mse: 944098.6875 - val_mae: 820.2873 - val_mape: 12112.4541 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 109113.0010 - mse: 109113.0078 - mae: 208.6561 - mape: 32.8680 - cosine: 1.0000 - val_loss: 1004791.4901 - val_mse: 1004792.1250 - val_mae: 823.6298 - val_mape: 12108.8379 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 108541.2953 - mse: 108541.2031 - mae: 207.9300 - mape: 32.7502 - cosine: 1.0000 - val_loss: 1041905.3535 - val_mse: 1041904.8125 - val_mae: 845.0019 - val_mape: 12442.9131 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108213.1200 - mse: 108212.7188 - mae: 207.6504 - mape: 32.6932 - cosine: 1.0000 - val_loss: 1046292.1951 - val_mse: 1046292.6875 - val_mae: 851.6810 - val_mape: 12551.7559 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107944.2035 - mse: 107944.1406 - mae: 207.2733 - mape: 32.6123 - cosine: 1.0000 - val_loss: 938786.3778 - val_mse: 938786.1875 - val_mae: 793.4578 - val_mape: 11661.0801 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 107588.1289 - mse: 107588.1797 - mae: 206.8481 - mape: 32.5381 - cosine: 1.0000 - val_loss: 1022106.7239 - val_mse: 1022105.8750 - val_mae: 844.4860 - val_mape: 12460.4043 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107313.3031 - mse: 107313.1484 - mae: 206.5529 - mape: 32.5310 - cosine: 1.0000 - val_loss: 1066163.0560 - val_mse: 1066163.7500 - val_mae: 849.0193 - val_mape: 12485.9727 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107067.1966 - mse: 107067.5781 - mae: 206.1551 - mape: 32.4107 - cosine: 1.0000 - val_loss: 1093945.0892 - val_mse: 1093944.3750 - val_mae: 869.1523 - val_mape: 12802.7334 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106676.4354 - mse: 106676.2109 - mae: 205.8861 - mape: 32.4115 - cosine: 1.0000 - val_loss: 1109613.1840 - val_mse: 1109614.0000 - val_mae: 869.1913 - val_mape: 12787.7031 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106447.8421 - mse: 106447.7500 - mae: 205.5976 - mape: 32.3543 - cosine: 1.0000 - val_loss: 1096831.2877 - val_mse: 1096832.6250 - val_mae: 861.1824 - val_mape: 12665.1426 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106264.5516 - mse: 106264.5938 - mae: 205.3787 - mape: 32.3340 - cosine: 1.0000 - val_loss: 1072384.0347 - val_mse: 1072383.1250 - val_mae: 861.6666 - val_mape: 12695.0156 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105941.1971 - mse: 105941.1406 - mae: 205.0126 - mape: 32.2486 - cosine: 1.0000 - val_loss: 1101616.1863 - val_mse: 1101617.0000 - val_mae: 875.9437 - val_mape: 12908.2451 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105730.1727 - mse: 105730.0234 - mae: 204.6666 - mape: 32.1760 - cosine: 1.0000 - val_loss: 1015693.6597 - val_mse: 1015694.9375 - val_mae: 829.8735 - val_mape: 12202.6143 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 61%|██████    | 22/36 [1:52:34<1:00:22, 258.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 159130.9641 - mse: 159131.0000 - mae: 256.6135 - mape: 42.2684 - cosine: 0.9998 - val_loss: 1051753.4819 - val_mse: 1051753.3750 - val_mae: 865.6165 - val_mape: 12809.8291 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 123457.4767 - mse: 123457.2578 - mae: 224.6215 - mape: 35.7529 - cosine: 1.0000 - val_loss: 1021827.4960 - val_mse: 1021827.1875 - val_mae: 837.6116 - val_mape: 12348.1426 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 118830.8448 - mse: 118830.8203 - mae: 219.1533 - mape: 34.6563 - cosine: 1.0000 - val_loss: 991456.7697 - val_mse: 991456.3750 - val_mae: 830.3178 - val_mape: 12244.8789 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 116589.8968 - mse: 116589.7812 - mae: 216.6062 - mape: 34.1904 - cosine: 1.0000 - val_loss: 1099201.6517 - val_mse: 1099201.2500 - val_mae: 859.3944 - val_mape: 12637.6377 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 114989.4314 - mse: 114989.5312 - mae: 214.8604 - mape: 33.8493 - cosine: 1.0000 - val_loss: 933740.9179 - val_mse: 933741.9375 - val_mae: 790.9899 - val_mape: 11627.5049 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 113360.5241 - mse: 113360.5781 - mae: 213.0640 - mape: 33.5656 - cosine: 1.0000 - val_loss: 954102.9395 - val_mse: 954103.2500 - val_mae: 808.1732 - val_mape: 11899.0645 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 111948.9713 - mse: 111948.9219 - mae: 211.5711 - mape: 33.3012 - cosine: 1.0000 - val_loss: 962502.7960 - val_mse: 962502.5625 - val_mae: 800.4488 - val_mape: 11761.0742 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 110683.5844 - mse: 110683.5469 - mae: 210.0544 - mape: 32.9773 - cosine: 1.0000 - val_loss: 958538.3008 - val_mse: 958538.3750 - val_mae: 805.1133 - val_mape: 11840.1602 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 109780.2299 - mse: 109780.2344 - mae: 209.0661 - mape: 32.8178 - cosine: 1.0000 - val_loss: 934255.9158 - val_mse: 934255.3125 - val_mae: 778.1906 - val_mape: 11409.0869 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 9s 7us/step - loss: 109022.7642 - mse: 109022.6406 - mae: 208.2538 - mape: 32.6934 - cosine: 1.0000 - val_loss: 935599.1560 - val_mse: 935598.8750 - val_mae: 802.9174 - val_mape: 11823.6299 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 108403.5314 - mse: 108403.4766 - mae: 207.6103 - mape: 32.5993 - cosine: 1.0000 - val_loss: 992951.6323 - val_mse: 992952.1250 - val_mae: 820.7328 - val_mape: 12069.8018 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107907.6429 - mse: 107907.5156 - mae: 207.0468 - mape: 32.5382 - cosine: 1.0000 - val_loss: 995983.9226 - val_mse: 995983.0000 - val_mae: 817.4797 - val_mape: 12010.3779 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107476.4742 - mse: 107476.3516 - mae: 206.6585 - mape: 32.4734 - cosine: 1.0000 - val_loss: 1032184.9879 - val_mse: 1032184.8750 - val_mae: 843.7166 - val_mape: 12428.1621 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 107014.9297 - mse: 107015.1484 - mae: 206.1829 - mape: 32.4150 - cosine: 1.0000 - val_loss: 1007020.0268 - val_mse: 1007020.0625 - val_mae: 848.1901 - val_mape: 12527.0371 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 106811.8582 - mse: 106811.7188 - mae: 205.9911 - mape: 32.4480 - cosine: 1.0000 - val_loss: 969852.0039 - val_mse: 969852.5000 - val_mae: 810.1954 - val_mape: 11911.4424 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 106464.3414 - mse: 106464.4453 - mae: 205.6888 - mape: 32.4056 - cosine: 1.0000 - val_loss: 1031344.5299 - val_mse: 1031343.9375 - val_mae: 826.9504 - val_mape: 12135.0889 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 106130.9700 - mse: 106130.9297 - mae: 205.2583 - mape: 32.3360 - cosine: 1.0000 - val_loss: 1023127.2687 - val_mse: 1023126.7500 - val_mae: 822.4169 - val_mape: 12076.1748 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 105708.7946 - mse: 105708.7500 - mae: 204.8182 - mape: 32.2876 - cosine: 1.0000 - val_loss: 1023242.2910 - val_mse: 1023242.3750 - val_mae: 836.3209 - val_mape: 12298.1592 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 105527.8259 - mse: 105527.6406 - mae: 204.5924 - mape: 32.2510 - cosine: 1.0000 - val_loss: 987141.6063 - val_mse: 987141.3750 - val_mae: 819.3388 - val_mape: 12051.1465 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 8s 7us/step - loss: 105292.1378 - mse: 105292.3125 - mae: 204.3451 - mape: 32.2066 - cosine: 1.0000 - val_loss: 1022716.3200 - val_mse: 1022716.3750 - val_mae: 826.4454 - val_mape: 12148.2168 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 64%|██████▍   | 23/36 [1:55:23<50:14, 231.91s/it]  \u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 139445.8895 - mse: 139445.9531 - mae: 239.8060 - mape: 38.5153 - cosine: 1.0000 - val_loss: 961373.8052 - val_mse: 961373.9375 - val_mae: 810.4029 - val_mape: 11931.2471 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 120129.6879 - mse: 120129.6797 - mae: 220.3568 - mape: 34.6140 - cosine: 1.0000 - val_loss: 955715.0499 - val_mse: 955714.8750 - val_mae: 825.3257 - val_mape: 12192.1611 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 115656.6193 - mse: 115656.4766 - mae: 215.5503 - mape: 33.9247 - cosine: 1.0000 - val_loss: 1135271.1858 - val_mse: 1135272.3750 - val_mae: 881.2433 - val_mape: 12974.0947 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 113067.6291 - mse: 113067.5234 - mae: 212.7108 - mape: 33.4628 - cosine: 1.0000 - val_loss: 1081847.3031 - val_mse: 1081847.7500 - val_mae: 868.9059 - val_mape: 12815.3770 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 111102.8240 - mse: 111102.9141 - mae: 210.6459 - mape: 33.1636 - cosine: 1.0000 - val_loss: 972353.7643 - val_mse: 972352.4375 - val_mae: 824.9562 - val_mape: 12167.6328 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 109920.9683 - mse: 109921.1328 - mae: 209.3438 - mape: 32.9764 - cosine: 1.0000 - val_loss: 1090814.7108 - val_mse: 1090815.6250 - val_mae: 844.4213 - val_mape: 12383.2617 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108987.9981 - mse: 108988.0703 - mae: 208.4445 - mape: 32.8500 - cosine: 1.0000 - val_loss: 985149.0421 - val_mse: 985149.1875 - val_mae: 830.8008 - val_mape: 12255.1709 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 108442.9990 - mse: 108443.2656 - mae: 207.8458 - mape: 32.7201 - cosine: 1.0000 - val_loss: 1157820.1258 - val_mse: 1157821.3750 - val_mae: 893.9434 - val_mape: 13166.0068 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107974.0589 - mse: 107973.9453 - mae: 207.3024 - mape: 32.6090 - cosine: 1.0000 - val_loss: 1010891.3608 - val_mse: 1010890.7500 - val_mae: 825.1474 - val_mape: 12131.0967 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107660.9188 - mse: 107660.8125 - mae: 206.9380 - mape: 32.5422 - cosine: 1.0000 - val_loss: 1057828.6067 - val_mse: 1057828.3750 - val_mae: 858.6611 - val_mape: 12653.9121 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 107142.1032 - mse: 107141.6562 - mae: 206.1901 - mape: 32.3945 - cosine: 1.0000 - val_loss: 922500.5462 - val_mse: 922500.7500 - val_mae: 790.0223 - val_mape: 11615.0488 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106712.8321 - mse: 106712.8438 - mae: 205.5376 - mape: 32.2437 - cosine: 1.0000 - val_loss: 1002153.9489 - val_mse: 1002154.8125 - val_mae: 808.9697 - val_mape: 11867.0146 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 106314.1823 - mse: 106314.3203 - mae: 205.1029 - mape: 32.1664 - cosine: 1.0000 - val_loss: 1052579.5847 - val_mse: 1052579.5000 - val_mae: 857.1229 - val_mape: 12636.2119 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105925.9107 - mse: 105925.9766 - mae: 204.5614 - mape: 32.0997 - cosine: 1.0000 - val_loss: 995426.1599 - val_mse: 995425.6250 - val_mae: 827.7728 - val_mape: 12179.0830 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105674.9278 - mse: 105675.0781 - mae: 204.2235 - mape: 32.0341 - cosine: 1.0000 - val_loss: 1090865.5497 - val_mse: 1090866.2500 - val_mae: 855.3652 - val_mape: 12564.3457 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 105376.7450 - mse: 105376.8984 - mae: 203.8057 - mape: 32.0088 - cosine: 1.0000 - val_loss: 1069558.0507 - val_mse: 1069557.5000 - val_mae: 857.1931 - val_mape: 12626.7334 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104893.9681 - mse: 104894.0000 - mae: 203.1586 - mape: 31.8643 - cosine: 1.0000 - val_loss: 1020001.6858 - val_mse: 1020002.3750 - val_mae: 825.0169 - val_mape: 12117.8320 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104529.0080 - mse: 104529.1875 - mae: 202.7731 - mape: 31.8358 - cosine: 1.0000 - val_loss: 1062536.4240 - val_mse: 1062535.8750 - val_mae: 844.8084 - val_mape: 12416.4199 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 14s 12us/step - loss: 104235.2832 - mse: 104235.2344 - mae: 202.4131 - mape: 31.7853 - cosine: 1.0000 - val_loss: 992815.6957 - val_mse: 992815.3750 - val_mae: 819.3024 - val_mape: 12041.7188 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 14s 13us/step - loss: 104096.3754 - mse: 104096.2969 - mae: 202.1883 - mape: 31.7226 - cosine: 1.0000 - val_loss: 1044558.6034 - val_mse: 1044556.6875 - val_mae: 845.8878 - val_mape: 12447.5439 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 67%|██████▋   | 24/36 [2:00:04<49:20, 246.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 138795.0281 - mse: 138795.5156 - mae: 239.0921 - mape: 38.5017 - cosine: 1.0000 - val_loss: 1060654.8949 - val_mse: 1060653.7500 - val_mae: 864.1498 - val_mape: 12763.9316 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 118918.1342 - mse: 118918.2656 - mae: 219.0709 - mape: 34.4408 - cosine: 1.0000 - val_loss: 1040742.2877 - val_mse: 1040741.2500 - val_mae: 844.0878 - val_mape: 12433.8389 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 24s 21us/step - loss: 116183.9312 - mse: 116183.9922 - mae: 215.9629 - mape: 33.8787 - cosine: 1.0000 - val_loss: 1029661.3180 - val_mse: 1029660.6875 - val_mae: 842.7623 - val_mape: 12421.6348 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 114318.2424 - mse: 114318.5859 - mae: 213.9158 - mape: 33.4683 - cosine: 1.0000 - val_loss: 1031005.9265 - val_mse: 1031005.6250 - val_mae: 846.9808 - val_mape: 12486.8447 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 112824.4153 - mse: 112824.2500 - mae: 212.3957 - mape: 33.2714 - cosine: 1.0000 - val_loss: 1073099.0683 - val_mse: 1073098.8750 - val_mae: 865.8700 - val_mape: 12766.2090 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 25s 21us/step - loss: 111557.9125 - mse: 111557.6250 - mae: 211.0415 - mape: 33.0684 - cosine: 1.0000 - val_loss: 914957.7540 - val_mse: 914957.0625 - val_mae: 780.1383 - val_mape: 11456.2354 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 110659.6328 - mse: 110659.9531 - mae: 210.1942 - mape: 32.9663 - cosine: 1.0000 - val_loss: 1065133.3285 - val_mse: 1065133.0000 - val_mae: 853.5491 - val_mape: 12566.0947 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 109925.7073 - mse: 109925.4609 - mae: 209.4494 - mape: 32.8516 - cosine: 1.0000 - val_loss: 1048110.0605 - val_mse: 1048111.0625 - val_mae: 843.3645 - val_mape: 12401.6689 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 109286.9415 - mse: 109287.1094 - mae: 208.7281 - mape: 32.7823 - cosine: 1.0000 - val_loss: 983797.5510 - val_mse: 983797.5625 - val_mae: 822.3436 - val_mape: 12111.6943 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 108616.5286 - mse: 108616.5625 - mae: 208.1010 - mape: 32.6888 - cosine: 1.0000 - val_loss: 1188157.4681 - val_mse: 1188155.6250 - val_mae: 888.2252 - val_mape: 13047.7090 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 25s 22us/step - loss: 107950.6670 - mse: 107950.1875 - mae: 207.2335 - mape: 32.5622 - cosine: 1.0000 - val_loss: 1048158.6283 - val_mse: 1048158.1875 - val_mae: 857.9186 - val_mape: 12648.9385 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 107344.1516 - mse: 107344.0391 - mae: 206.5557 - mape: 32.4563 - cosine: 1.0000 - val_loss: 969640.5525 - val_mse: 969639.4375 - val_mae: 802.3864 - val_mape: 11778.9844 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 106766.0234 - mse: 106766.0938 - mae: 205.9199 - mape: 32.3786 - cosine: 1.0000 - val_loss: 1092386.4729 - val_mse: 1092386.7500 - val_mae: 875.1104 - val_mape: 12909.4746 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 106282.4701 - mse: 106282.5703 - mae: 205.3832 - mape: 32.2720 - cosine: 1.0000 - val_loss: 996333.9825 - val_mse: 996331.8125 - val_mae: 814.7889 - val_mape: 11965.8896 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 105926.9055 - mse: 105926.6016 - mae: 204.8825 - mape: 32.1835 - cosine: 1.0000 - val_loss: 1001491.7227 - val_mse: 1001491.0625 - val_mae: 817.9491 - val_mape: 12012.0537 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 105487.4824 - mse: 105487.3516 - mae: 204.4003 - mape: 32.0916 - cosine: 1.0000 - val_loss: 1074876.2255 - val_mse: 1074876.5000 - val_mae: 861.5550 - val_mape: 12687.3105 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 105083.9036 - mse: 105083.5625 - mae: 203.8393 - mape: 31.9809 - cosine: 1.0000 - val_loss: 1075020.2695 - val_mse: 1075020.2500 - val_mae: 854.8768 - val_mape: 12576.5713 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 104777.5968 - mse: 104777.5625 - mae: 203.4543 - mape: 31.9636 - cosine: 1.0000 - val_loss: 1083757.0002 - val_mse: 1083757.8750 - val_mae: 865.4625 - val_mape: 12752.4014 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 104490.7839 - mse: 104490.7578 - mae: 203.1375 - mape: 31.8950 - cosine: 1.0000 - val_loss: 1012507.8898 - val_mse: 1012507.5000 - val_mae: 823.9321 - val_mape: 12109.5752 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 104252.6692 - mse: 104252.7344 - mae: 202.8252 - mape: 31.8350 - cosine: 1.0000 - val_loss: 1037863.3645 - val_mse: 1037864.4375 - val_mae: 838.3017 - val_mape: 12321.8145 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 69%|██████▉   | 25/36 [2:08:37<59:51, 326.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 160175.8623 - mse: 160175.8281 - mae: 258.3544 - mape: 41.9881 - cosine: 0.9992 - val_loss: 1022931.1804 - val_mse: 1022930.8750 - val_mae: 847.9662 - val_mape: 12527.2080 - val_cosine: 0.9988\n","Epoch 2/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 131105.6911 - mse: 131106.2031 - mae: 233.2556 - mape: 36.7994 - cosine: 0.9984 - val_loss: 971573.6422 - val_mse: 971573.9375 - val_mae: 821.1344 - val_mape: 12112.5195 - val_cosine: 0.9986\n","Epoch 3/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 125694.6339 - mse: 125694.5938 - mae: 227.6165 - mape: 35.6452 - cosine: 0.9983 - val_loss: 1019522.2752 - val_mse: 1019521.2500 - val_mae: 851.0259 - val_mape: 12571.4404 - val_cosine: 0.9982\n","Epoch 4/20\n","1156982/1156982 [==============================] - 26s 23us/step - loss: 121900.4219 - mse: 121900.6406 - mae: 222.9528 - mape: 34.6519 - cosine: 0.9983 - val_loss: 969382.1078 - val_mse: 969382.2500 - val_mae: 828.8442 - val_mape: 12237.3418 - val_cosine: 0.9988\n","Epoch 5/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 119620.1525 - mse: 119620.3125 - mae: 220.0065 - mape: 34.1630 - cosine: 0.9988 - val_loss: 1045711.8471 - val_mse: 1045713.6875 - val_mae: 844.0528 - val_mape: 12417.9600 - val_cosine: 0.9992\n","Epoch 6/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 118436.4178 - mse: 118436.2812 - mae: 218.6338 - mape: 33.9245 - cosine: 0.9990 - val_loss: 972857.8230 - val_mse: 972859.5000 - val_mae: 804.2056 - val_mape: 11802.8477 - val_cosine: 0.9977\n","Epoch 7/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 117397.1284 - mse: 117397.1250 - mae: 217.3520 - mape: 33.6876 - cosine: 0.9992 - val_loss: 939563.5266 - val_mse: 939564.8125 - val_mae: 804.8149 - val_mape: 11849.9512 - val_cosine: 0.9987\n","Epoch 8/20\n","1156982/1156982 [==============================] - 27s 24us/step - loss: 116463.9638 - mse: 116463.8906 - mae: 216.2971 - mape: 33.5113 - cosine: 0.9993 - val_loss: 1031054.6640 - val_mse: 1031054.9375 - val_mae: 846.3991 - val_mape: 12475.5244 - val_cosine: 0.9996\n","Epoch 9/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 115442.3273 - mse: 115442.4844 - mae: 215.1565 - mape: 33.3174 - cosine: 0.9993 - val_loss: 939329.4754 - val_mse: 939330.3125 - val_mae: 802.4686 - val_mape: 11807.1396 - val_cosine: 0.9992\n","Epoch 10/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 114581.8328 - mse: 114581.9922 - mae: 214.1043 - mape: 33.1338 - cosine: 0.9994 - val_loss: 982189.8140 - val_mse: 982190.1250 - val_mae: 823.4443 - val_mape: 12124.9287 - val_cosine: 0.9995\n","Epoch 11/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 113773.4061 - mse: 113773.4844 - mae: 213.3215 - mape: 32.9903 - cosine: 0.9994 - val_loss: 998009.5792 - val_mse: 998010.3750 - val_mae: 819.3825 - val_mape: 12040.1260 - val_cosine: 0.9993\n","Epoch 12/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 113118.7572 - mse: 113119.0547 - mae: 212.6542 - mape: 32.8995 - cosine: 0.9994 - val_loss: 1057085.5426 - val_mse: 1057085.1250 - val_mae: 852.0840 - val_mape: 12542.1367 - val_cosine: 0.9997\n","Epoch 13/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 112405.7091 - mse: 112405.4297 - mae: 211.9265 - mape: 32.8156 - cosine: 0.9995 - val_loss: 1072059.1266 - val_mse: 1072061.3750 - val_mae: 862.5483 - val_mape: 12712.9033 - val_cosine: 0.9998\n","Epoch 14/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 111909.4370 - mse: 111909.5625 - mae: 211.4566 - mape: 32.7523 - cosine: 0.9995 - val_loss: 1051628.3426 - val_mse: 1051628.1250 - val_mae: 853.3395 - val_mape: 12572.8936 - val_cosine: 0.9998\n","Epoch 15/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 111397.4456 - mse: 111396.9531 - mae: 210.8430 - mape: 32.6669 - cosine: 0.9995 - val_loss: 977816.1832 - val_mse: 977816.4375 - val_mae: 818.7579 - val_mape: 12043.3574 - val_cosine: 0.9992\n","Epoch 16/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 110939.7105 - mse: 110939.3828 - mae: 210.3652 - mape: 32.5908 - cosine: 0.9996 - val_loss: 1000316.2469 - val_mse: 1000315.9375 - val_mae: 824.6054 - val_mape: 12125.9238 - val_cosine: 0.9995\n","Epoch 17/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 110553.2720 - mse: 110553.4609 - mae: 210.0497 - mape: 32.5757 - cosine: 0.9996 - val_loss: 1017645.8491 - val_mse: 1017645.1875 - val_mae: 846.8534 - val_mape: 12490.3730 - val_cosine: 0.9998\n","Epoch 18/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 110246.4899 - mse: 110246.4688 - mae: 209.7374 - mape: 32.5391 - cosine: 0.9996 - val_loss: 1009473.5959 - val_mse: 1009473.5000 - val_mae: 836.0839 - val_mape: 12315.0107 - val_cosine: 0.9999\n","Epoch 19/20\n","1156982/1156982 [==============================] - 28s 25us/step - loss: 109886.1049 - mse: 109886.1094 - mae: 209.3668 - mape: 32.4607 - cosine: 0.9997 - val_loss: 1092255.7663 - val_mse: 1092256.1250 - val_mae: 879.9163 - val_mape: 12993.8301 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 109563.0927 - mse: 109562.8047 - mae: 209.0408 - mape: 32.4446 - cosine: 0.9997 - val_loss: 1006746.6734 - val_mse: 1006746.6875 - val_mae: 819.7430 - val_mape: 12036.6738 - val_cosine: 0.9996\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 72%|███████▏  | 26/36 [2:17:47<1:05:35, 393.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 141056.2352 - mse: 141056.5156 - mae: 241.9467 - mape: 39.1246 - cosine: 1.0000 - val_loss: 1118459.9033 - val_mse: 1118460.8750 - val_mae: 872.3157 - val_mape: 12851.2627 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 27s 24us/step - loss: 121974.0399 - mse: 121973.7969 - mae: 222.6879 - mape: 35.2434 - cosine: 1.0000 - val_loss: 996412.4971 - val_mse: 996412.9375 - val_mae: 828.6708 - val_mape: 12211.3506 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 118469.4071 - mse: 118469.4922 - mae: 218.5220 - mape: 34.5431 - cosine: 1.0000 - val_loss: 1130927.4993 - val_mse: 1130926.7500 - val_mae: 880.0225 - val_mape: 12965.9014 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 115931.5445 - mse: 115931.6406 - mae: 215.6854 - mape: 34.0400 - cosine: 1.0000 - val_loss: 1057027.3834 - val_mse: 1057026.7500 - val_mae: 860.0369 - val_mape: 12685.6758 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 28s 25us/step - loss: 113462.6552 - mse: 113462.7422 - mae: 213.2042 - mape: 33.6491 - cosine: 1.0000 - val_loss: 956282.1569 - val_mse: 956281.0000 - val_mae: 797.1351 - val_mape: 11711.0986 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 111320.8716 - mse: 111320.7969 - mae: 211.1656 - mape: 33.3637 - cosine: 1.0000 - val_loss: 1188926.9025 - val_mse: 1188924.2500 - val_mae: 897.3892 - val_mape: 13200.1465 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 110190.4235 - mse: 110190.5234 - mae: 210.1100 - mape: 33.1751 - cosine: 1.0000 - val_loss: 1064782.6135 - val_mse: 1064783.2500 - val_mae: 844.7009 - val_mape: 12415.5723 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 27s 24us/step - loss: 109327.1570 - mse: 109327.1250 - mae: 209.1270 - mape: 33.0410 - cosine: 1.0000 - val_loss: 1101480.7600 - val_mse: 1101483.2500 - val_mae: 868.3967 - val_mape: 12786.1602 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 108590.1124 - mse: 108590.1875 - mae: 208.3230 - mape: 32.8863 - cosine: 1.0000 - val_loss: 961137.7386 - val_mse: 961137.0625 - val_mae: 805.1016 - val_mape: 11834.9238 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 108103.2659 - mse: 108103.1406 - mae: 207.7515 - mape: 32.7617 - cosine: 1.0000 - val_loss: 995212.9585 - val_mse: 995213.4375 - val_mae: 833.6667 - val_mape: 12295.9209 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107598.9648 - mse: 107598.7109 - mae: 207.1942 - mape: 32.6518 - cosine: 1.0000 - val_loss: 994286.2087 - val_mse: 994286.1875 - val_mae: 818.5303 - val_mape: 12024.4453 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 107229.1730 - mse: 107229.2422 - mae: 206.8259 - mape: 32.5600 - cosine: 1.0000 - val_loss: 965243.7787 - val_mse: 965243.3125 - val_mae: 807.2735 - val_mape: 11865.1318 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 106821.3828 - mse: 106821.2266 - mae: 206.2544 - mape: 32.4965 - cosine: 1.0000 - val_loss: 975047.8123 - val_mse: 975047.5625 - val_mae: 816.8600 - val_mape: 12027.4082 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 106565.7804 - mse: 106565.8281 - mae: 206.0091 - mape: 32.4504 - cosine: 1.0000 - val_loss: 1049720.4769 - val_mse: 1049719.8750 - val_mae: 847.7957 - val_mape: 12483.9814 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 106237.8820 - mse: 106237.8750 - mae: 205.5298 - mape: 32.3638 - cosine: 1.0000 - val_loss: 941872.1030 - val_mse: 941872.6875 - val_mae: 793.8049 - val_mape: 11658.1025 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 105772.6787 - mse: 105772.8125 - mae: 204.9779 - mape: 32.2677 - cosine: 1.0000 - val_loss: 1184867.7866 - val_mse: 1184866.7500 - val_mae: 897.1214 - val_mape: 13193.1426 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 105402.1441 - mse: 105402.5234 - mae: 204.5039 - mape: 32.1878 - cosine: 1.0000 - val_loss: 971631.1759 - val_mse: 971630.0000 - val_mae: 814.5302 - val_mape: 11986.9775 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 105139.0211 - mse: 105138.7266 - mae: 204.1323 - mape: 32.1290 - cosine: 1.0000 - val_loss: 1032404.9657 - val_mse: 1032403.5000 - val_mae: 835.8093 - val_mape: 12287.7930 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 26s 22us/step - loss: 104736.9540 - mse: 104736.9141 - mae: 203.7259 - mape: 32.0432 - cosine: 1.0000 - val_loss: 1058550.4387 - val_mse: 1058551.7500 - val_mae: 841.2304 - val_mape: 12349.6416 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 27s 23us/step - loss: 104507.6097 - mse: 104507.6250 - mae: 203.4383 - mape: 31.9926 - cosine: 1.0000 - val_loss: 919440.6343 - val_mse: 919439.5625 - val_mae: 791.1755 - val_mape: 11639.7324 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 75%|███████▌  | 27/36 [2:27:01<1:06:15, 441.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 142647.1671 - mse: 142646.7031 - mae: 242.6249 - mape: 39.1977 - cosine: 0.9999 - val_loss: 1010069.2956 - val_mse: 1010069.8750 - val_mae: 838.3989 - val_mape: 12368.2471 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 121292.7854 - mse: 121292.9375 - mae: 221.8712 - mape: 35.1380 - cosine: 1.0000 - val_loss: 1040015.3376 - val_mse: 1040016.5625 - val_mae: 857.8398 - val_mape: 12671.7852 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 117750.9284 - mse: 117750.5703 - mae: 217.6147 - mape: 34.3261 - cosine: 1.0000 - val_loss: 948610.4482 - val_mse: 948610.5000 - val_mae: 808.8000 - val_mape: 11910.5205 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115845.0646 - mse: 115844.8203 - mae: 215.3792 - mape: 33.9058 - cosine: 1.0000 - val_loss: 1087516.9224 - val_mse: 1087515.1250 - val_mae: 875.7473 - val_mape: 12927.2480 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 114394.2568 - mse: 114394.0781 - mae: 213.7090 - mape: 33.5825 - cosine: 1.0000 - val_loss: 1077904.2543 - val_mse: 1077905.5000 - val_mae: 848.0140 - val_mape: 12470.6396 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 113083.5497 - mse: 113083.5391 - mae: 212.4549 - mape: 33.4379 - cosine: 1.0000 - val_loss: 928832.4088 - val_mse: 928831.9375 - val_mae: 807.6478 - val_mape: 11922.5566 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 111646.7237 - mse: 111646.4297 - mae: 210.9080 - mape: 33.1799 - cosine: 1.0000 - val_loss: 990177.1410 - val_mse: 990176.8750 - val_mae: 823.4042 - val_mape: 12115.0283 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110333.0098 - mse: 110332.8594 - mae: 209.7159 - mape: 32.9585 - cosine: 1.0000 - val_loss: 1019140.3106 - val_mse: 1019141.5000 - val_mae: 850.6042 - val_mape: 12559.2412 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 109414.5799 - mse: 109414.3359 - mae: 208.7722 - mape: 32.8138 - cosine: 1.0000 - val_loss: 997873.8424 - val_mse: 997873.1875 - val_mae: 835.9847 - val_mape: 12314.4492 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108670.7740 - mse: 108670.5703 - mae: 208.0680 - mape: 32.7241 - cosine: 1.0000 - val_loss: 1027162.3288 - val_mse: 1027162.2500 - val_mae: 835.4047 - val_mape: 12284.7383 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 108132.1869 - mse: 108132.0781 - mae: 207.4871 - mape: 32.6267 - cosine: 1.0000 - val_loss: 1009621.7034 - val_mse: 1009622.8125 - val_mae: 821.7209 - val_mape: 12068.2314 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107645.1807 - mse: 107645.1953 - mae: 207.0838 - mape: 32.5811 - cosine: 1.0000 - val_loss: 1015150.3095 - val_mse: 1015150.9375 - val_mae: 833.3245 - val_mape: 12265.5352 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 107273.5511 - mse: 107273.3516 - mae: 206.7415 - mape: 32.5159 - cosine: 1.0000 - val_loss: 975073.8965 - val_mse: 975074.3750 - val_mae: 802.8120 - val_mape: 11776.4395 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 106897.1496 - mse: 106897.0000 - mae: 206.3542 - mape: 32.4603 - cosine: 1.0000 - val_loss: 1041523.7705 - val_mse: 1041523.1875 - val_mae: 840.0751 - val_mape: 12351.9561 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 106561.5887 - mse: 106561.7500 - mae: 205.9183 - mape: 32.3975 - cosine: 1.0000 - val_loss: 970086.8106 - val_mse: 970087.6875 - val_mae: 810.7537 - val_mape: 11916.0986 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 106233.2152 - mse: 106233.3203 - mae: 205.5484 - mape: 32.3268 - cosine: 1.0000 - val_loss: 971342.7154 - val_mse: 971342.1250 - val_mae: 804.9295 - val_mape: 11819.4551 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105940.1491 - mse: 105940.0859 - mae: 205.3013 - mape: 32.2892 - cosine: 1.0000 - val_loss: 1082942.4689 - val_mse: 1082941.7500 - val_mae: 843.7363 - val_mape: 12375.3770 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 15s 13us/step - loss: 105590.4399 - mse: 105590.3984 - mae: 204.9449 - mape: 32.2543 - cosine: 1.0000 - val_loss: 967206.2874 - val_mse: 967205.8750 - val_mae: 810.2396 - val_mape: 11920.3877 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105402.2556 - mse: 105402.0781 - mae: 204.6287 - mape: 32.1780 - cosine: 1.0000 - val_loss: 1110615.2559 - val_mse: 1110615.5000 - val_mae: 861.9714 - val_mape: 12669.9873 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105138.0335 - mse: 105138.1016 - mae: 204.4270 - mape: 32.1748 - cosine: 1.0000 - val_loss: 1023706.9913 - val_mse: 1023707.4375 - val_mae: 834.9246 - val_mape: 12278.5703 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 78%|███████▊  | 28/36 [2:32:09<53:34, 401.76s/it]  \u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 141480.4047 - mse: 141480.6250 - mae: 240.9904 - mape: 38.4134 - cosine: 0.9998 - val_loss: 993199.1356 - val_mse: 993198.2500 - val_mae: 813.8705 - val_mape: 11959.8418 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 120346.3044 - mse: 120346.3047 - mae: 220.7517 - mape: 34.8973 - cosine: 1.0000 - val_loss: 955105.1875 - val_mse: 955105.6250 - val_mae: 801.2959 - val_mape: 11787.0117 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 28s 25us/step - loss: 118205.3350 - mse: 118205.1328 - mae: 218.1374 - mape: 34.4752 - cosine: 1.0000 - val_loss: 1021318.5634 - val_mse: 1021317.7500 - val_mae: 845.3179 - val_mape: 12470.7861 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 116539.5415 - mse: 116539.6328 - mae: 216.0022 - mape: 33.9857 - cosine: 1.0000 - val_loss: 950365.3223 - val_mse: 950365.4375 - val_mae: 803.9733 - val_mape: 11835.1855 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 115019.9754 - mse: 115020.0078 - mae: 214.1274 - mape: 33.5374 - cosine: 1.0000 - val_loss: 1006385.9517 - val_mse: 1006385.0625 - val_mae: 837.7590 - val_mape: 12356.5283 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 113743.5397 - mse: 113743.4453 - mae: 212.5293 - mape: 33.1465 - cosine: 1.0000 - val_loss: 945874.3139 - val_mse: 945873.6875 - val_mae: 788.8304 - val_mape: 11571.9561 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 112785.4012 - mse: 112785.3984 - mae: 211.4315 - mape: 32.9337 - cosine: 1.0000 - val_loss: 1292541.9058 - val_mse: 1292540.8750 - val_mae: 946.3625 - val_mape: 13949.6572 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 112046.7140 - mse: 112046.4062 - mae: 210.6841 - mape: 32.8229 - cosine: 1.0000 - val_loss: 1076661.2476 - val_mse: 1076661.8750 - val_mae: 841.2075 - val_mape: 12341.0859 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 111332.4064 - mse: 111332.2266 - mae: 209.8798 - mape: 32.6738 - cosine: 1.0000 - val_loss: 1023810.8171 - val_mse: 1023812.5625 - val_mae: 849.8888 - val_mape: 12542.6191 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 110480.3896 - mse: 110480.2734 - mae: 209.0527 - mape: 32.5344 - cosine: 1.0000 - val_loss: 1078263.7688 - val_mse: 1078264.5000 - val_mae: 868.5304 - val_mape: 12805.7539 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 109698.9267 - mse: 109698.9219 - mae: 208.4043 - mape: 32.4822 - cosine: 1.0000 - val_loss: 977139.9830 - val_mse: 977138.7500 - val_mae: 818.9161 - val_mape: 12051.7764 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 109063.4522 - mse: 109063.6641 - mae: 207.7835 - mape: 32.4013 - cosine: 1.0000 - val_loss: 1021818.7509 - val_mse: 1021818.9375 - val_mae: 829.9452 - val_mape: 12197.0781 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 108359.0762 - mse: 108359.0781 - mae: 207.1528 - mape: 32.3349 - cosine: 1.0000 - val_loss: 1012108.8706 - val_mse: 1012110.0625 - val_mae: 826.8052 - val_mape: 12158.4688 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107750.4230 - mse: 107750.4844 - mae: 206.5889 - mape: 32.2814 - cosine: 1.0000 - val_loss: 1054073.5783 - val_mse: 1054072.8750 - val_mae: 859.1123 - val_mape: 12668.3740 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107309.1024 - mse: 107308.8047 - mae: 206.1103 - mape: 32.2259 - cosine: 1.0000 - val_loss: 1029600.4166 - val_mse: 1029599.1875 - val_mae: 833.2306 - val_mape: 12246.9873 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 106906.6011 - mse: 106906.1641 - mae: 205.6592 - mape: 32.1598 - cosine: 1.0000 - val_loss: 1009578.3608 - val_mse: 1009577.0625 - val_mae: 815.6277 - val_mape: 11977.5889 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106591.2136 - mse: 106590.9219 - mae: 205.2193 - mape: 32.0809 - cosine: 1.0000 - val_loss: 1033759.7335 - val_mse: 1033758.6250 - val_mae: 821.6227 - val_mape: 12061.5039 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 106272.1344 - mse: 106271.8984 - mae: 204.9220 - mape: 32.0639 - cosine: 1.0000 - val_loss: 992455.0716 - val_mse: 992455.1250 - val_mae: 815.7672 - val_mape: 11981.2021 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 105992.6577 - mse: 105992.8203 - mae: 204.5692 - mape: 31.9895 - cosine: 1.0000 - val_loss: 996885.3797 - val_mse: 996884.5625 - val_mae: 814.0979 - val_mape: 11942.6484 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 105770.8407 - mse: 105771.1172 - mae: 204.3329 - mape: 31.9310 - cosine: 1.0000 - val_loss: 994600.8175 - val_mse: 994599.7500 - val_mae: 813.9907 - val_mape: 11952.5469 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 81%|████████  | 29/36 [2:41:41<52:48, 452.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 10s 9us/step - loss: 1137034.4224 - mse: 1137035.6250 - mae: 838.9211 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 2/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4245 - mse: 1137033.6250 - mae: 838.9208 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 3/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4229 - mse: 1137035.1250 - mae: 838.9199 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 4/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4235 - mse: 1137032.8750 - mae: 838.9200 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 5/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4224 - mse: 1137035.3750 - mae: 838.9208 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 6/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4225 - mse: 1137034.6250 - mae: 838.9210 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 7/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4236 - mse: 1137033.2500 - mae: 838.9207 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 8/20\n","1156982/1156982 [==============================] - 10s 9us/step - loss: 1137034.4235 - mse: 1137036.0000 - mae: 838.9210 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 9/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4228 - mse: 1137035.6250 - mae: 838.9209 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 10/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4239 - mse: 1137034.3750 - mae: 838.9199 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 11/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4245 - mse: 1137032.0000 - mae: 838.9203 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 12/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4246 - mse: 1137034.8750 - mae: 838.9200 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 13/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4240 - mse: 1137034.1250 - mae: 838.9202 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 14/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4230 - mse: 1137035.2500 - mae: 838.9199 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 15/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4241 - mse: 1137034.0000 - mae: 838.9205 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 16/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4233 - mse: 1137034.1250 - mae: 838.9200 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 17/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4223 - mse: 1137034.7500 - mae: 838.9207 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 18/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4243 - mse: 1137035.6250 - mae: 838.9202 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 19/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 1137034.4241 - mse: 1137033.7500 - mae: 838.9205 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n","Epoch 20/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 1137034.4224 - mse: 1137034.7500 - mae: 838.9218 - mape: 100.0000 - cosine: 0.0000e+00 - val_loss: 42.4964 - val_mse: 42.4964 - val_mae: 6.4770 - val_mape: 100.0000 - val_cosine: 0.0000e+00\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 83%|████████▎ | 30/36 [2:44:53<37:27, 374.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 148396.1102 - mse: 148395.6562 - mae: 249.9258 - mape: 41.2035 - cosine: 0.9991 - val_loss: 989374.1726 - val_mse: 989374.1250 - val_mae: 822.0471 - val_mape: 12122.6309 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 13us/step - loss: 125401.6673 - mse: 125401.6719 - mae: 227.2461 - mape: 36.2693 - cosine: 1.0000 - val_loss: 1132394.6426 - val_mse: 1132395.1250 - val_mae: 893.9621 - val_mape: 13208.7900 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 120253.3113 - mse: 120253.1953 - mae: 220.6626 - mape: 34.9066 - cosine: 1.0000 - val_loss: 1027452.9197 - val_mse: 1027453.0625 - val_mae: 838.8910 - val_mape: 12358.2188 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 117508.7770 - mse: 117508.6484 - mae: 217.6999 - mape: 34.4218 - cosine: 1.0000 - val_loss: 1098742.6233 - val_mse: 1098743.7500 - val_mae: 887.5767 - val_mape: 13122.9736 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115744.0041 - mse: 115744.0781 - mae: 215.9169 - mape: 34.2214 - cosine: 1.0000 - val_loss: 1040791.2303 - val_mse: 1040790.5625 - val_mae: 838.6885 - val_mape: 12342.8164 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 114059.3694 - mse: 114059.2422 - mae: 214.2033 - mape: 33.9827 - cosine: 1.0000 - val_loss: 1083143.2469 - val_mse: 1083142.2500 - val_mae: 859.0019 - val_mape: 12640.9541 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 112626.7452 - mse: 112626.7656 - mae: 212.7735 - mape: 33.7780 - cosine: 1.0000 - val_loss: 1121558.8305 - val_mse: 1121558.7500 - val_mae: 873.6332 - val_mape: 12854.9697 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111625.3569 - mse: 111625.4609 - mae: 211.6853 - mape: 33.6232 - cosine: 1.0000 - val_loss: 1043656.4837 - val_mse: 1043656.6875 - val_mae: 859.8149 - val_mape: 12696.3018 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110610.1676 - mse: 110610.1406 - mae: 210.3630 - mape: 33.3901 - cosine: 1.0000 - val_loss: 997736.0217 - val_mse: 997737.8125 - val_mae: 813.5591 - val_mape: 11953.6504 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109452.8489 - mse: 109452.8828 - mae: 208.6928 - mape: 32.9548 - cosine: 1.0000 - val_loss: 1046229.8908 - val_mse: 1046230.5000 - val_mae: 848.7201 - val_mape: 12495.1416 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108960.2849 - mse: 108960.3828 - mae: 208.1283 - mape: 32.7892 - cosine: 1.0000 - val_loss: 1043121.0418 - val_mse: 1043121.6250 - val_mae: 836.8365 - val_mape: 12299.2764 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108278.7787 - mse: 108278.7656 - mae: 207.3597 - mape: 32.6256 - cosine: 1.0000 - val_loss: 983798.6836 - val_mse: 983798.8125 - val_mae: 825.3073 - val_mape: 12153.2178 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107667.9202 - mse: 107668.0234 - mae: 206.6775 - mape: 32.5279 - cosine: 1.0000 - val_loss: 1066503.2496 - val_mse: 1066504.5000 - val_mae: 863.2646 - val_mape: 12730.0840 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107243.0149 - mse: 107242.9609 - mae: 206.1042 - mape: 32.3860 - cosine: 1.0000 - val_loss: 1005051.7278 - val_mse: 1005051.2500 - val_mae: 827.9860 - val_mape: 12182.4922 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106758.3854 - mse: 106758.3359 - mae: 205.6125 - mape: 32.3413 - cosine: 1.0000 - val_loss: 968027.1019 - val_mse: 968027.9375 - val_mae: 822.9922 - val_mape: 12139.9893 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106266.4450 - mse: 106266.5859 - mae: 205.2191 - mape: 32.2770 - cosine: 1.0000 - val_loss: 1011520.2308 - val_mse: 1011520.3125 - val_mae: 820.9561 - val_mape: 12057.7852 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105959.4948 - mse: 105959.3984 - mae: 204.8714 - mape: 32.2545 - cosine: 1.0000 - val_loss: 994792.6654 - val_mse: 994792.2500 - val_mae: 811.4507 - val_mape: 11907.3701 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105690.7225 - mse: 105690.5547 - mae: 204.6243 - mape: 32.2231 - cosine: 1.0000 - val_loss: 1072469.7047 - val_mse: 1072469.0000 - val_mae: 860.6322 - val_mape: 12677.2695 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105493.6364 - mse: 105493.7891 - mae: 204.3207 - mape: 32.1750 - cosine: 1.0000 - val_loss: 1006588.1543 - val_mse: 1006588.0000 - val_mae: 819.8633 - val_mape: 12037.9043 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105184.9083 - mse: 105184.8984 - mae: 203.9307 - mape: 32.0992 - cosine: 1.0000 - val_loss: 1072767.9201 - val_mse: 1072767.5000 - val_mae: 838.8604 - val_mape: 12302.6787 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 86%|████████▌ | 31/36 [2:50:13<29:50, 358.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 211489.4611 - mse: 211489.6250 - mae: 299.4081 - mape: 51.0842 - cosine: 1.0000 - val_loss: 989355.8487 - val_mse: 989355.6875 - val_mae: 837.9736 - val_mape: 12406.5293 - val_cosine: 0.9997\n","Epoch 2/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 139271.6314 - mse: 139271.7812 - mae: 240.6180 - mape: 38.0034 - cosine: 0.9996 - val_loss: 973787.6412 - val_mse: 973788.5625 - val_mae: 817.8694 - val_mape: 12057.7344 - val_cosine: 0.9992\n","Epoch 3/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 133584.2241 - mse: 133583.9531 - mae: 234.9619 - mape: 37.0339 - cosine: 0.9993 - val_loss: 1000278.2798 - val_mse: 1000277.1875 - val_mae: 841.4232 - val_mape: 12434.7256 - val_cosine: 0.9994\n","Epoch 4/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 129119.3277 - mse: 129119.5000 - mae: 230.7466 - mape: 36.4440 - cosine: 0.9995 - val_loss: 958266.8791 - val_mse: 958267.0625 - val_mae: 816.9783 - val_mape: 12055.8584 - val_cosine: 0.9997\n","Epoch 5/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 125367.9584 - mse: 125368.1797 - mae: 226.5589 - mape: 35.6767 - cosine: 0.9999 - val_loss: 969121.9554 - val_mse: 969122.9375 - val_mae: 814.6860 - val_mape: 12001.4473 - val_cosine: 0.9999\n","Epoch 6/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 122381.9697 - mse: 122381.9297 - mae: 223.1166 - mape: 34.9515 - cosine: 0.9999 - val_loss: 1015398.1308 - val_mse: 1015398.4375 - val_mae: 839.3685 - val_mape: 12376.9482 - val_cosine: 0.9999\n","Epoch 7/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 120595.2135 - mse: 120595.2266 - mae: 220.8807 - mape: 34.4288 - cosine: 0.9999 - val_loss: 1003320.7420 - val_mse: 1003321.0000 - val_mae: 834.1063 - val_mape: 12300.3506 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 119365.6678 - mse: 119365.4688 - mae: 219.3531 - mape: 34.1461 - cosine: 1.0000 - val_loss: 1000519.6122 - val_mse: 1000518.8125 - val_mae: 829.4174 - val_mape: 12216.7695 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 118472.4865 - mse: 118472.5078 - mae: 218.2119 - mape: 33.9522 - cosine: 1.0000 - val_loss: 973957.5873 - val_mse: 973956.9375 - val_mae: 804.8259 - val_mape: 11822.0820 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 117750.1292 - mse: 117750.3281 - mae: 217.2970 - mape: 33.8241 - cosine: 1.0000 - val_loss: 1037436.4740 - val_mse: 1037436.5625 - val_mae: 847.9062 - val_mape: 12498.1035 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 117188.9223 - mse: 117188.9531 - mae: 216.5774 - mape: 33.7003 - cosine: 1.0000 - val_loss: 1016590.1445 - val_mse: 1016589.3750 - val_mae: 833.2010 - val_mape: 12266.3721 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 116736.7319 - mse: 116736.7109 - mae: 215.9869 - mape: 33.5790 - cosine: 1.0000 - val_loss: 1013927.0095 - val_mse: 1013927.5625 - val_mae: 840.8298 - val_mape: 12400.0381 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 116291.0973 - mse: 116291.1094 - mae: 215.5044 - mape: 33.5161 - cosine: 1.0000 - val_loss: 1037415.7898 - val_mse: 1037415.8125 - val_mae: 841.2460 - val_mape: 12381.5176 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 115895.4700 - mse: 115895.5391 - mae: 214.9982 - mape: 33.4042 - cosine: 1.0000 - val_loss: 1069945.7255 - val_mse: 1069945.6250 - val_mae: 865.2905 - val_mape: 12771.3760 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 115469.8693 - mse: 115469.9609 - mae: 214.4612 - mape: 33.3144 - cosine: 1.0000 - val_loss: 992129.2830 - val_mse: 992129.0625 - val_mae: 829.8337 - val_mape: 12226.8271 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 115147.8389 - mse: 115147.7969 - mae: 214.0512 - mape: 33.2466 - cosine: 1.0000 - val_loss: 1042368.9015 - val_mse: 1042368.7500 - val_mae: 846.0045 - val_mape: 12462.6123 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 10s 8us/step - loss: 114748.6789 - mse: 114748.6719 - mae: 213.5463 - mape: 33.1553 - cosine: 1.0000 - val_loss: 973948.4515 - val_mse: 973947.7500 - val_mae: 810.5540 - val_mape: 11917.2607 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 114469.2022 - mse: 114469.3750 - mae: 213.2081 - mape: 33.0891 - cosine: 1.0000 - val_loss: 1062700.9708 - val_mse: 1062701.6250 - val_mae: 864.8588 - val_mape: 12766.0947 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 114153.1538 - mse: 114153.0859 - mae: 212.7979 - mape: 32.9963 - cosine: 1.0000 - val_loss: 1019999.3638 - val_mse: 1019999.7500 - val_mae: 838.0332 - val_mape: 12341.4561 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 9s 8us/step - loss: 113839.8320 - mse: 113839.8125 - mae: 212.3938 - mape: 32.9102 - cosine: 1.0000 - val_loss: 1010881.1717 - val_mse: 1010881.1250 - val_mae: 834.7645 - val_mape: 12298.7256 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 89%|████████▉ | 32/36 [2:53:22<20:29, 307.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 30s 26us/step - loss: 146221.4244 - mse: 146221.7812 - mae: 245.3855 - mape: 39.1110 - cosine: 0.9990 - val_loss: 997170.8168 - val_mse: 997171.5000 - val_mae: 845.4057 - val_mape: 12504.7578 - val_cosine: 0.9991\n","Epoch 2/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 123284.4672 - mse: 123284.5625 - mae: 224.2342 - mape: 34.9201 - cosine: 0.9995 - val_loss: 937065.7244 - val_mse: 937065.8125 - val_mae: 788.6547 - val_mape: 11575.4531 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 119075.3095 - mse: 119075.2812 - mae: 219.1490 - mape: 34.0976 - cosine: 1.0000 - val_loss: 1074241.3174 - val_mse: 1074241.0000 - val_mae: 866.8876 - val_mape: 12787.3105 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 117090.8993 - mse: 117090.8438 - mae: 216.8042 - mape: 33.8037 - cosine: 1.0000 - val_loss: 957832.3611 - val_mse: 957832.5000 - val_mae: 820.4730 - val_mape: 12113.1445 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 115802.7782 - mse: 115803.1016 - mae: 215.2750 - mape: 33.6441 - cosine: 1.0000 - val_loss: 973413.0241 - val_mse: 973411.8125 - val_mae: 816.5267 - val_mape: 12030.8848 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 114641.3445 - mse: 114641.5625 - mae: 213.9937 - mape: 33.4943 - cosine: 1.0000 - val_loss: 1029320.4009 - val_mse: 1029319.5000 - val_mae: 852.8452 - val_mape: 12591.4814 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 113287.8099 - mse: 113287.6641 - mae: 212.4917 - mape: 33.3112 - cosine: 1.0000 - val_loss: 1014669.8534 - val_mse: 1014670.3750 - val_mae: 807.0532 - val_mape: 11823.2393 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 112133.5601 - mse: 112133.2812 - mae: 211.2686 - mape: 33.1015 - cosine: 1.0000 - val_loss: 1053820.5167 - val_mse: 1053820.0000 - val_mae: 855.7222 - val_mape: 12619.4434 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 111345.3839 - mse: 111345.4141 - mae: 210.5737 - mape: 32.9997 - cosine: 1.0000 - val_loss: 996130.6610 - val_mse: 996131.8750 - val_mae: 824.3124 - val_mape: 12133.4688 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 110522.2899 - mse: 110522.5156 - mae: 209.7051 - mape: 32.8377 - cosine: 1.0000 - val_loss: 953275.8141 - val_mse: 953274.6875 - val_mae: 809.4832 - val_mape: 11917.2080 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 109926.3855 - mse: 109926.6562 - mae: 209.0892 - mape: 32.7448 - cosine: 1.0000 - val_loss: 973171.0165 - val_mse: 973171.0625 - val_mae: 816.4805 - val_mape: 12018.8848 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 109330.3182 - mse: 109330.5547 - mae: 208.5526 - mape: 32.6651 - cosine: 1.0000 - val_loss: 981657.1089 - val_mse: 981656.3125 - val_mae: 822.2490 - val_mape: 12106.8984 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 108703.7098 - mse: 108703.3906 - mae: 207.8579 - mape: 32.5757 - cosine: 1.0000 - val_loss: 1045055.5305 - val_mse: 1045056.0625 - val_mae: 840.9467 - val_mape: 12367.2949 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 108377.3331 - mse: 108377.2344 - mae: 207.4675 - mape: 32.5061 - cosine: 1.0000 - val_loss: 976248.9668 - val_mse: 976247.8125 - val_mae: 828.5717 - val_mape: 12216.9180 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 108035.3586 - mse: 108035.5000 - mae: 207.0260 - mape: 32.4352 - cosine: 1.0000 - val_loss: 974859.8936 - val_mse: 974859.5000 - val_mae: 837.8030 - val_mape: 12383.8789 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107666.7103 - mse: 107667.2188 - mae: 206.7280 - mape: 32.3872 - cosine: 1.0000 - val_loss: 1035072.7930 - val_mse: 1035072.8125 - val_mae: 836.1652 - val_mape: 12291.9238 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107263.5366 - mse: 107263.4531 - mae: 206.3188 - mape: 32.3367 - cosine: 1.0000 - val_loss: 950335.5743 - val_mse: 950334.7500 - val_mae: 801.4603 - val_mape: 11780.6406 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106970.8167 - mse: 106970.5859 - mae: 205.9986 - mape: 32.3127 - cosine: 1.0000 - val_loss: 986809.3786 - val_mse: 986809.7500 - val_mae: 817.9048 - val_mape: 12030.9531 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106741.3369 - mse: 106741.5625 - mae: 205.7966 - mape: 32.2784 - cosine: 1.0000 - val_loss: 1016529.3872 - val_mse: 1016529.1875 - val_mae: 824.9598 - val_mape: 12114.8457 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106458.6746 - mse: 106458.5156 - mae: 205.4918 - mape: 32.2300 - cosine: 1.0000 - val_loss: 957495.2990 - val_mse: 957495.2500 - val_mae: 800.8713 - val_mape: 11768.1982 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 92%|█████████▏| 33/36 [3:03:02<19:27, 389.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 145134.6237 - mse: 145134.4531 - mae: 243.6321 - mape: 39.0027 - cosine: 0.9945 - val_loss: 975584.1994 - val_mse: 975585.3125 - val_mae: 803.5449 - val_mape: 11807.4111 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 119436.3431 - mse: 119436.4922 - mae: 219.1011 - mape: 34.4473 - cosine: 1.0000 - val_loss: 1007091.5129 - val_mse: 1007091.3125 - val_mae: 837.2007 - val_mape: 12346.7568 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 116541.4805 - mse: 116541.5234 - mae: 215.8556 - mape: 33.8052 - cosine: 1.0000 - val_loss: 986690.3346 - val_mse: 986690.4375 - val_mae: 822.1122 - val_mape: 12104.1328 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 114468.1264 - mse: 114468.2891 - mae: 213.7965 - mape: 33.4404 - cosine: 1.0000 - val_loss: 988798.9918 - val_mse: 988798.6250 - val_mae: 808.6509 - val_mape: 11874.1445 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 113234.4660 - mse: 113234.5078 - mae: 212.5785 - mape: 33.2880 - cosine: 1.0000 - val_loss: 993711.7914 - val_mse: 993710.4375 - val_mae: 829.5786 - val_mape: 12229.8447 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 28s 24us/step - loss: 112169.8645 - mse: 112169.8438 - mae: 211.6960 - mape: 33.1676 - cosine: 1.0000 - val_loss: 943205.7053 - val_mse: 943205.9375 - val_mae: 801.8128 - val_mape: 11800.4004 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 111267.1048 - mse: 111266.9141 - mae: 210.7368 - mape: 33.0396 - cosine: 1.0000 - val_loss: 964266.7643 - val_mse: 964267.1250 - val_mae: 817.6785 - val_mape: 12049.8916 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 110578.7479 - mse: 110578.4531 - mae: 210.1135 - mape: 32.9552 - cosine: 1.0000 - val_loss: 1101666.7849 - val_mse: 1101666.5000 - val_mae: 867.2802 - val_mape: 12773.8721 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 109918.5540 - mse: 109918.6016 - mae: 209.5536 - mape: 32.9116 - cosine: 1.0000 - val_loss: 1011218.7890 - val_mse: 1011217.1250 - val_mae: 837.7982 - val_mape: 12341.8076 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 28s 25us/step - loss: 109484.6490 - mse: 109484.4609 - mae: 209.1062 - mape: 32.8845 - cosine: 1.0000 - val_loss: 997398.6043 - val_mse: 997399.1875 - val_mae: 818.3727 - val_mape: 12032.8574 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 108956.2694 - mse: 108956.2422 - mae: 208.6361 - mape: 32.8368 - cosine: 1.0000 - val_loss: 1073293.5471 - val_mse: 1073292.7500 - val_mae: 850.9162 - val_mape: 12515.2988 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 108540.2357 - mse: 108540.3672 - mae: 208.2069 - mape: 32.8112 - cosine: 1.0000 - val_loss: 1040121.4205 - val_mse: 1040121.0000 - val_mae: 828.5950 - val_mape: 12159.0996 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 108228.0341 - mse: 108228.0547 - mae: 207.9850 - mape: 32.7463 - cosine: 1.0000 - val_loss: 1053379.4399 - val_mse: 1053380.1250 - val_mae: 838.8225 - val_mape: 12331.6455 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107873.5408 - mse: 107873.5469 - mae: 207.5214 - mape: 32.7517 - cosine: 1.0000 - val_loss: 994940.8632 - val_mse: 994941.4375 - val_mae: 825.4637 - val_mape: 12150.5029 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107608.4374 - mse: 107608.3438 - mae: 207.2617 - mape: 32.6755 - cosine: 1.0000 - val_loss: 1104965.3399 - val_mse: 1104963.6250 - val_mae: 867.4517 - val_mape: 12767.2852 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 107240.7519 - mse: 107240.9062 - mae: 206.8099 - mape: 32.5974 - cosine: 1.0000 - val_loss: 1043192.2029 - val_mse: 1043190.5625 - val_mae: 852.8688 - val_mape: 12571.6074 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106952.8605 - mse: 106952.6484 - mae: 206.4925 - mape: 32.5201 - cosine: 1.0000 - val_loss: 1094958.5828 - val_mse: 1094958.3750 - val_mae: 847.1061 - val_mape: 12441.1748 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106643.5559 - mse: 106643.4297 - mae: 206.0889 - mape: 32.4839 - cosine: 1.0000 - val_loss: 1081743.1937 - val_mse: 1081740.2500 - val_mae: 848.2076 - val_mape: 12461.8750 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 29s 25us/step - loss: 106418.3417 - mse: 106418.3672 - mae: 205.7219 - mape: 32.3943 - cosine: 1.0000 - val_loss: 999153.1275 - val_mse: 999154.3750 - val_mae: 822.5444 - val_mape: 12093.2900 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 28s 25us/step - loss: 106168.0748 - mse: 106168.0000 - mae: 205.4274 - mape: 32.3442 - cosine: 1.0000 - val_loss: 998103.1377 - val_mse: 998103.0625 - val_mae: 817.8704 - val_mape: 12019.1816 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 94%|█████████▍| 34/36 [3:12:36<14:49, 444.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 153231.8979 - mse: 153232.0625 - mae: 253.8325 - mape: 42.0760 - cosine: 1.0000 - val_loss: 954980.1090 - val_mse: 954979.1875 - val_mae: 811.9496 - val_mape: 11980.3564 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 123312.8055 - mse: 123312.6641 - mae: 224.5657 - mape: 35.5381 - cosine: 1.0000 - val_loss: 957880.7967 - val_mse: 957881.8750 - val_mae: 817.5709 - val_mape: 12066.2646 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 119029.6620 - mse: 119029.6406 - mae: 219.1374 - mape: 34.4701 - cosine: 1.0000 - val_loss: 1053170.7420 - val_mse: 1053171.0000 - val_mae: 864.5370 - val_mape: 12778.4404 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115640.4794 - mse: 115640.3359 - mae: 215.5383 - mape: 33.9080 - cosine: 1.0000 - val_loss: 1063989.7278 - val_mse: 1063988.8750 - val_mae: 854.8645 - val_mape: 12592.4365 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 113069.0193 - mse: 113068.8281 - mae: 212.7989 - mape: 33.4820 - cosine: 1.0000 - val_loss: 970315.1653 - val_mse: 970314.9375 - val_mae: 822.2783 - val_mape: 12125.8271 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111691.5456 - mse: 111691.5781 - mae: 211.4870 - mape: 33.3409 - cosine: 1.0000 - val_loss: 946558.9397 - val_mse: 946558.7500 - val_mae: 799.8016 - val_mape: 11760.4541 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110711.5612 - mse: 110711.5078 - mae: 210.5540 - mape: 33.2123 - cosine: 1.0000 - val_loss: 986337.4573 - val_mse: 986338.2500 - val_mae: 821.8401 - val_mape: 12097.6504 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109934.7683 - mse: 109934.7031 - mae: 209.7828 - mape: 33.1040 - cosine: 1.0000 - val_loss: 1130812.8480 - val_mse: 1130813.2500 - val_mae: 891.5167 - val_mape: 13165.3691 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109189.8274 - mse: 109189.9609 - mae: 209.0334 - mape: 32.9602 - cosine: 1.0000 - val_loss: 1021354.2489 - val_mse: 1021352.7500 - val_mae: 826.6058 - val_mape: 12145.7158 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108596.0115 - mse: 108595.9141 - mae: 208.3237 - mape: 32.8239 - cosine: 1.0000 - val_loss: 1074105.7632 - val_mse: 1074105.5000 - val_mae: 867.3065 - val_mape: 12794.5459 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108160.2737 - mse: 108160.1016 - mae: 207.8123 - mape: 32.7048 - cosine: 1.0000 - val_loss: 985844.2264 - val_mse: 985845.1250 - val_mae: 818.9675 - val_mape: 12044.5186 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107666.1281 - mse: 107665.9844 - mae: 207.2769 - mape: 32.6160 - cosine: 1.0000 - val_loss: 1017555.3169 - val_mse: 1017555.2500 - val_mae: 835.6051 - val_mape: 12298.6855 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107358.3145 - mse: 107358.2266 - mae: 206.8883 - mape: 32.5144 - cosine: 1.0000 - val_loss: 1057059.7842 - val_mse: 1057059.7500 - val_mae: 849.0793 - val_mape: 12495.4023 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106970.5821 - mse: 106970.7812 - mae: 206.3749 - mape: 32.4272 - cosine: 1.0000 - val_loss: 1045984.9633 - val_mse: 1045985.6875 - val_mae: 839.2199 - val_mape: 12333.5479 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106735.6872 - mse: 106735.4062 - mae: 206.2056 - mape: 32.4115 - cosine: 1.0000 - val_loss: 939448.6616 - val_mse: 939448.0000 - val_mae: 802.9280 - val_mape: 11816.6816 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106429.6610 - mse: 106429.7344 - mae: 205.7773 - mape: 32.2920 - cosine: 1.0000 - val_loss: 1069615.5559 - val_mse: 1069615.3750 - val_mae: 855.8682 - val_mape: 12596.0088 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106065.7220 - mse: 106065.7344 - mae: 205.3037 - mape: 32.1913 - cosine: 1.0000 - val_loss: 1023401.1586 - val_mse: 1023401.6875 - val_mae: 818.1957 - val_mape: 11999.1260 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105586.8752 - mse: 105586.7109 - mae: 204.5551 - mape: 32.0351 - cosine: 1.0000 - val_loss: 1025637.8586 - val_mse: 1025637.1875 - val_mae: 833.9149 - val_mape: 12266.7510 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105216.6966 - mse: 105216.7109 - mae: 204.0196 - mape: 31.9175 - cosine: 1.0000 - val_loss: 980674.0584 - val_mse: 980674.3125 - val_mae: 817.2598 - val_mape: 12022.8340 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 104794.9143 - mse: 104795.1016 - mae: 203.5423 - mape: 31.8746 - cosine: 1.0000 - val_loss: 1029792.6100 - val_mse: 1029793.0000 - val_mae: 829.4404 - val_mape: 12180.5068 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n"," 97%|█████████▋| 35/36 [3:18:00<06:48, 408.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 126)               2772      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4064      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                2112      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 9,013\n","Trainable params: 9,013\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 1156982 samples, validate on 289246 samples\n","Epoch 1/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 138265.4365 - mse: 138265.5156 - mae: 238.2367 - mape: 38.2048 - cosine: 1.0000 - val_loss: 897577.5986 - val_mse: 897577.5000 - val_mae: 791.9701 - val_mape: 11686.3057 - val_cosine: 1.0000\n","Epoch 2/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 119818.3592 - mse: 119818.2969 - mae: 219.9072 - mape: 34.6364 - cosine: 1.0000 - val_loss: 986663.1157 - val_mse: 986663.3750 - val_mae: 806.6642 - val_mape: 11848.3770 - val_cosine: 1.0000\n","Epoch 3/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 117763.8967 - mse: 117764.0781 - mae: 217.4030 - mape: 34.1966 - cosine: 1.0000 - val_loss: 946197.3052 - val_mse: 946197.2500 - val_mae: 803.4801 - val_mape: 11827.4131 - val_cosine: 1.0000\n","Epoch 4/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 116257.0463 - mse: 116257.0547 - mae: 215.7825 - mape: 33.9196 - cosine: 1.0000 - val_loss: 1112491.0381 - val_mse: 1112490.2500 - val_mae: 890.0887 - val_mape: 13159.7559 - val_cosine: 1.0000\n","Epoch 5/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 115116.0654 - mse: 115115.9375 - mae: 214.4929 - mape: 33.7249 - cosine: 1.0000 - val_loss: 967001.1195 - val_mse: 967001.3125 - val_mae: 809.5840 - val_mape: 11907.1768 - val_cosine: 1.0000\n","Epoch 6/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 114080.8908 - mse: 114080.8750 - mae: 213.2088 - mape: 33.5178 - cosine: 1.0000 - val_loss: 1031025.2130 - val_mse: 1031026.6250 - val_mae: 831.8501 - val_mape: 12228.1094 - val_cosine: 1.0000\n","Epoch 7/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 113431.2763 - mse: 113431.5000 - mae: 212.6048 - mape: 33.4707 - cosine: 1.0000 - val_loss: 985839.0204 - val_mse: 985839.1250 - val_mae: 813.7159 - val_mape: 11961.3945 - val_cosine: 1.0000\n","Epoch 8/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 112678.6589 - mse: 112678.6953 - mae: 211.8781 - mape: 33.3570 - cosine: 1.0000 - val_loss: 1025433.4509 - val_mse: 1025432.6875 - val_mae: 843.1638 - val_mape: 12427.1797 - val_cosine: 1.0000\n","Epoch 9/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111955.6053 - mse: 111955.6250 - mae: 211.2277 - mape: 33.2948 - cosine: 1.0000 - val_loss: 944935.2806 - val_mse: 944935.1875 - val_mae: 786.3074 - val_mape: 11533.5840 - val_cosine: 1.0000\n","Epoch 10/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 111160.4825 - mse: 111160.3281 - mae: 210.3973 - mape: 33.1609 - cosine: 1.0000 - val_loss: 996995.0431 - val_mse: 996994.0625 - val_mae: 819.2684 - val_mape: 12044.6924 - val_cosine: 1.0000\n","Epoch 11/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 110197.1560 - mse: 110197.1562 - mae: 209.4530 - mape: 33.0316 - cosine: 1.0000 - val_loss: 980604.2757 - val_mse: 980603.3125 - val_mae: 807.4805 - val_mape: 11859.1719 - val_cosine: 1.0000\n","Epoch 12/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 109219.5199 - mse: 109219.5391 - mae: 208.5109 - mape: 32.8934 - cosine: 1.0000 - val_loss: 1018272.9864 - val_mse: 1018271.7500 - val_mae: 819.4625 - val_mape: 12035.6963 - val_cosine: 1.0000\n","Epoch 13/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 108409.5064 - mse: 108409.4688 - mae: 207.7347 - mape: 32.8033 - cosine: 1.0000 - val_loss: 938408.2184 - val_mse: 938408.8125 - val_mae: 785.4515 - val_mape: 11527.7764 - val_cosine: 1.0000\n","Epoch 14/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107811.4487 - mse: 107811.2812 - mae: 207.0467 - mape: 32.6755 - cosine: 1.0000 - val_loss: 1065106.9326 - val_mse: 1065106.2500 - val_mae: 857.8201 - val_mape: 12633.5049 - val_cosine: 1.0000\n","Epoch 15/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107358.1552 - mse: 107358.2109 - mae: 206.6352 - mape: 32.6502 - cosine: 1.0000 - val_loss: 1012597.4663 - val_mse: 1012598.4375 - val_mae: 839.2125 - val_mape: 12373.6406 - val_cosine: 1.0000\n","Epoch 16/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 107007.9541 - mse: 107007.8594 - mae: 206.2335 - mape: 32.5323 - cosine: 1.0000 - val_loss: 973282.9305 - val_mse: 973283.1250 - val_mae: 820.0008 - val_mape: 12077.2217 - val_cosine: 1.0000\n","Epoch 17/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106653.4075 - mse: 106653.2734 - mae: 205.9898 - mape: 32.5362 - cosine: 1.0000 - val_loss: 977243.8839 - val_mse: 977243.8750 - val_mae: 802.1921 - val_mape: 11774.9922 - val_cosine: 1.0000\n","Epoch 18/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106409.3347 - mse: 106409.4844 - mae: 205.7304 - mape: 32.4700 - cosine: 1.0000 - val_loss: 1008965.8873 - val_mse: 1008965.6250 - val_mae: 827.0368 - val_mape: 12164.9033 - val_cosine: 1.0000\n","Epoch 19/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 106093.6028 - mse: 106093.4453 - mae: 205.3200 - mape: 32.3688 - cosine: 1.0000 - val_loss: 960349.9203 - val_mse: 960349.3750 - val_mae: 809.4437 - val_mape: 11908.6826 - val_cosine: 1.0000\n","Epoch 20/20\n","1156982/1156982 [==============================] - 16s 14us/step - loss: 105861.8951 - mse: 105861.8359 - mae: 205.0835 - mape: 32.3378 - cosine: 1.0000 - val_loss: 1092601.7217 - val_mse: 1092599.7500 - val_mae: 864.6178 - val_mape: 12727.6885 - val_cosine: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 36/36 [3:23:23<00:00, 382.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eKrV5oa5L9LR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"241c2dd5-a467-4b5f-a1db-3e1a73d16e28","executionInfo":{"status":"ok","timestamp":1580721584790,"user_tz":-60,"elapsed":769,"user":{"displayName":"Pietro Colombo","photoUrl":"","userId":"03586676689308284073"}}},"source":["len(train_scaled_x)%3"],"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"id":"K-ot4wGTWTae","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwKGcQWvDQ9P","colab_type":"text"},"source":["# Testing the model"]},{"cell_type":"code","metadata":{"id":"gQStrsKSqCpY","colab_type":"code","outputId":"643ff76d-10f7-4af0-b311-afcc8168fc88","executionInfo":{"status":"ok","timestamp":1580397536966,"user_tz":-60,"elapsed":546,"user":{"displayName":"Carlo Radice","photoUrl":"","userId":"09973400932884829292"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["hist = pd.DataFrame(history.history)\n","hist['epoch'] = history.epoch\n","hist.tail()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>mean_squared_error</th>\n","      <th>mean_absolute_error</th>\n","      <th>mean_absolute_percentage_error</th>\n","      <th>cosine_proximity</th>\n","      <th>epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>95</th>\n","      <td>0.117497</td>\n","      <td>0.117497</td>\n","      <td>0.250207</td>\n","      <td>4.004454</td>\n","      <td>-1.0</td>\n","      <td>95</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>0.117456</td>\n","      <td>0.117456</td>\n","      <td>0.250099</td>\n","      <td>4.003096</td>\n","      <td>-1.0</td>\n","      <td>96</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>0.117400</td>\n","      <td>0.117400</td>\n","      <td>0.250057</td>\n","      <td>4.002487</td>\n","      <td>-1.0</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>0.117321</td>\n","      <td>0.117321</td>\n","      <td>0.249879</td>\n","      <td>3.999507</td>\n","      <td>-1.0</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>0.117229</td>\n","      <td>0.117229</td>\n","      <td>0.249832</td>\n","      <td>3.998828</td>\n","      <td>-1.0</td>\n","      <td>99</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        loss  mean_squared_error  ...  cosine_proximity  epoch\n","95  0.117497            0.117497  ...              -1.0     95\n","96  0.117456            0.117456  ...              -1.0     96\n","97  0.117400            0.117400  ...              -1.0     97\n","98  0.117321            0.117321  ...              -1.0     98\n","99  0.117229            0.117229  ...              -1.0     99\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"EO2Wo2jHg1j7","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","n_epochs = 25\n","x_plot = list(range(1,n_epochs+1))\n","\n","def plot_history(network_history):\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.plot(x_plot, network_history.history['loss'])\n","    plt.plot(x_plot, network_history.history['val_loss'])\n","    plt.legend(['Training', 'Validation'])\n","\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('cosine_proximity')\n","    plt.plot(x_plot, network_history.history['cosine_proximity'])\n","    plt.plot(x_plot, network_history.history['val_cosine_proximity'])\n","    plt.legend(['Training', 'Validation'])\n","\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('mean_absolute_error')\n","    plt.plot(x_plot, network_history.history['mean_absolute_error'])\n","    plt.plot(x_plot, network_history.history['val_mean_absolute_error'])\n","    plt.legend(['Training', 'Validation'])\n","\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('mean_absolute_percentage_error')\n","    plt.plot(x_plot, network_history.history['mean_absolute_percentage_error'])\n","    plt.plot(x_plot, network_history.history['val_mean_absolute_percentage_error'])\n","    plt.legend(['Training', 'Validation'])\n","\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('mean_squared_error')\n","    plt.plot(x_plot, network_history.history['mean_squared_error'])\n","    plt.plot(x_plot, network_history.history['val_mean_squared_error'])\n","    plt.legend(['Training', 'Validation'])\n","\n","plot_history(hist)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8pQ4TZIFo_ME","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","!pip install git+https://github.com/tensorflow/docs\n","print(tf.__version__)\n","import tensorflow_docs as tfdocs\n","import tensorflow_docs.plots\n","import tensorflow_docs.modeling\n","\n","plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n","plotter.plot({'Basic': history}, metric = \"mean_absolute_error\")\n","plt.ylim([0, 10])\n","plt.ylabel('MAE [MPG]')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVkn5-DtTjeC","colab_type":"code","outputId":"d73b6804-5fb2-462b-efcf-e66bf21083fa","executionInfo":{"status":"error","timestamp":1579531607591,"user_tz":-60,"elapsed":629,"user":{"displayName":"Pietro Colombo","photoUrl":"","userId":"03586676689308284073"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["from matplotlib import pyplot\n","\n","# plot metrics\n","pyplot.plot(history.history['mean_squared_error'])\n","pyplot.plot(history.history['mean_absolute_error'])\n","pyplot.plot(history.history['mean_absolute_percentage_error'])\n","pyplot.plot(history.history['cosine_proximity'])\n","pyplot.show()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-133-0b786dc0ec15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plot metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_percentage_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'mean_squared_error'"]}]},{"cell_type":"code","metadata":{"id":"6VEwZYR2KJQT","colab_type":"code","colab":{}},"source":["pred = model.predict(test_scaled_x)\n","pred = pred.flatten()\n","pred = np.exp(pred)+1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfaClgP9pSdz","colab_type":"code","outputId":"7b61f149-f8d3-4087-97e4-313d183a0382","executionInfo":{"status":"ok","timestamp":1580395628416,"user_tz":-60,"elapsed":6905,"user":{"displayName":"Carlo Radice","photoUrl":"","userId":"09973400932884829292"}},"colab":{"base_uri":"https://localhost:8080/","height":284}},"source":["import matplotlib.pyplot as plt\n","\n","a = plt.axes(aspect='equal')\n","plt.scatter(test_y, pred)\n","plt.xlabel('True Values [trip_duration]')\n","plt.ylabel('Predictions [trip_duration]')\n","lims = [0, 18000]\n","plt.xlim(lims)\n","plt.ylim(lims)\n","_ = plt.plot(lims, lims)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAR0AAAELCAYAAADk5VL9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRcdxnJry/wEjDSKASEb70gAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"vMcHuQ9YR5g9","colab_type":"code","outputId":"6c484b0b-7009-49af-ee26-7e0294d1f639","executionInfo":{"status":"ok","timestamp":1580395629271,"user_tz":-60,"elapsed":804,"user":{"displayName":"Carlo Radice","photoUrl":"","userId":"09973400932884829292"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Root Mean Squared Logarithmic Error\n","np.sqrt(np.mean(np.square(np.log(pred + 1) - np.log(test_y + 1)), axis=-1))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3430566070977301"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"markdown","metadata":{"id":"sp5RNhkFWtfT","colab_type":"text"},"source":["# Prediction\n"]},{"cell_type":"code","metadata":{"id":"k05PFiTOXBr9","colab_type":"code","colab":{}},"source":["# carlo\n","test_weather_osm = pd.read_csv(\"/content/drive/My Drive/universita/magistrale/advanced_machine_learning/Progetto AML/test_weather_osm_50_clusters.csv\")\n","test_weather_osm = test_weather_osm.drop(columns=['id'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"301KVm3xFeo5","colab_type":"code","outputId":"f7a86448-8026-4be2-c2aa-58b436ebb8d1","executionInfo":{"status":"ok","timestamp":1580398483884,"user_tz":-60,"elapsed":700,"user":{"displayName":"Carlo Radice","photoUrl":"","userId":"09973400932884829292"}},"colab":{"base_uri":"https://localhost:8080/","height":226}},"source":["test_weather_osm.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>total_distance</th>\n","      <th>total_travel_time</th>\n","      <th>number_of_steps</th>\n","      <th>maximum_temperature</th>\n","      <th>minimum_temperature</th>\n","      <th>average_temperature</th>\n","      <th>precipitation</th>\n","      <th>snow_fall</th>\n","      <th>snow_depth</th>\n","      <th>vendor_id</th>\n","      <th>passenger_count</th>\n","      <th>store_and_fwd_flag</th>\n","      <th>pickup_cluster</th>\n","      <th>dropoff_cluster</th>\n","      <th>JFK_start</th>\n","      <th>JFK_end</th>\n","      <th>guardia_start</th>\n","      <th>guardia_end</th>\n","      <th>pickup_hour</th>\n","      <th>pickup_minute</th>\n","      <th>pickup_day_week</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1497.1</td>\n","      <td>200.2</td>\n","      <td>7</td>\n","      <td>13.333333</td>\n","      <td>10.555556</td>\n","      <td>11.944444</td>\n","      <td>1.5494</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>48</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>13</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1427.1</td>\n","      <td>141.5</td>\n","      <td>2</td>\n","      <td>30.555556</td>\n","      <td>22.777778</td>\n","      <td>26.666667</td>\n","      <td>0.0000</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>36</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>18</td>\n","      <td>45</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2312.3</td>\n","      <td>324.6</td>\n","      <td>9</td>\n","      <td>2.222222</td>\n","      <td>-2.777778</td>\n","      <td>-0.277778</td>\n","      <td>0.0000</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>23</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>48</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>931.8</td>\n","      <td>84.2</td>\n","      <td>4</td>\n","      <td>5.000000</td>\n","      <td>-1.111111</td>\n","      <td>1.944444</td>\n","      <td>0.0000</td>\n","      <td>0.0</td>\n","      <td>15.24</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>39</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>20</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2501.7</td>\n","      <td>294.7</td>\n","      <td>8</td>\n","      <td>30.555556</td>\n","      <td>22.777778</td>\n","      <td>26.666667</td>\n","      <td>0.0000</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>29</td>\n","      <td>46</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>13</td>\n","      <td>37</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   total_distance  total_travel_time  ...  pickup_minute  pickup_day_week\n","0          1497.1              200.2  ...              2                5\n","1          1427.1              141.5  ...             45                4\n","2          2312.3              324.6  ...             48                3\n","3           931.8               84.2  ...             20                4\n","4          2501.7              294.7  ...             37                4\n","\n","[5 rows x 21 columns]"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"8EFzs858XHEt","colab_type":"code","colab":{}},"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","test_weather_osm_array = np.array(test_weather_osm)\n","\n","test_weather_osm_scaled_x = scaler.transform(test_weather_osm_array)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"44Hf4OPPXqjz","colab_type":"code","colab":{}},"source":["pred = model.predict(test_weather_osm_scaled_x)\n","pred = pred.flatten()\n","pred = np.exp(pred)+1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HM3AqzCiXrxg","colab_type":"code","colab":{}},"source":["test_weather_osm = pd.read_csv(\"/content/drive/My Drive/universita/magistrale/advanced_machine_learning/Progetto AML/test_weather_osm_50_clusters.csv\")\n","\n","test_weather_osm['trip_duration'] = pred.tolist()\n","\n","test_weather_osm[['id', 'trip_duration']].to_csv('neural_submission_50_clusters.csv', index=False)\n","# pietro\n","#!cp /content/neural_submission.csv \"/content/drive/My Drive/UnimiB/Magistrale/Secondo Anno/Advanced Machine Learning/Progetto AML/\"\n","# carlo\n","!cp /content/neural_submission_50_clusters.csv \"/content/drive/My Drive/universita/magistrale/advanced_machine_learning/Progetto AML/\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGlAKpPFoIts","colab_type":"code","outputId":"242702be-b754-471f-aeca-c9bb3c8f72e3","executionInfo":{"status":"ok","timestamp":1580395665411,"user_tz":-60,"elapsed":13711,"user":{"displayName":"Carlo Radice","photoUrl":"","userId":"09973400932884829292"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_weather_osm.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(625134, 23)"]},"metadata":{"tags":[]},"execution_count":88}]}]}